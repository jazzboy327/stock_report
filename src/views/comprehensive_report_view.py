# src/views/comprehensive_report_view.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import logging
from datetime import datetime
import json
import requests
import base64
import io
import matplotlib.pyplot as plt
import traceback
import os
from dotenv import load_dotenv
import time

logger = logging.getLogger('StockAnalysisApp.ComprehensiveReportView')


class ComprehensiveReportView:
    """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ë·°ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        """ë·° ì´ˆê¸°í™”"""
        # .env íŒŒì¼ ë¡œë“œ ì‹œë„
        load_dotenv()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self._initialize_data_store()

        # ì£¼ê°€ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
        from src.utils.stock_price_predictor import StockPricePredictor
        self.price_predictor = StockPricePredictor()

    def _initialize_data_store(self):
        """ë°ì´í„° ì €ì¥ì†Œ ì´ˆê¸°í™” - í™•ì¥ëœ ê¸°ê°„ ë° ê¸°ëŠ¥ ì¶”ê°€"""
        if 'comprehensive_data' not in st.session_state:
            st.session_state.comprehensive_data = {
                'stock_detail': {},
                'technical_analysis': {},
                'investor_trends': {},
                'financial_analysis': {
                    'risk_metrics': {},
                    'growth_data': {}
                },
                'trading_signals': {},
                'prediction_result': None,
                'last_update': {},
                'analysis_cache': {}
            }

        if 'report_options' not in st.session_state:
            st.session_state.report_options = {
                'has_generated': False,
                'llm_model': 'gpt-4o',
                'temperature': 0.7,
                'max_tokens': 2000,
                'include_prediction': True,  # ì£¼ê°€ ì˜ˆì¸¡ í¬í•¨ ì—¬ë¶€ ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
                'language': 'í•œêµ­ì–´',  # ì–¸ì–´ ì˜µì…˜ ì¶”ê°€
                'analysis_depth': 'ê³ ê¸‰'  # ë¶„ì„ ê¹Šì´ ì˜µì…˜ ì¶”ê°€
            }

        # ì£¼ê°€ ì˜ˆì¸¡ ê´€ë ¨ ëª¨ë¸ ì„¤ì • ì´ˆê¸°í™”
        if 'model_settings' not in st.session_state:
            st.session_state.model_settings = {
                'prediction_days': 30,
                'model_type': 'LSTM',
                'use_ensemble': False,
                'train_size': 0.8,
                'use_auto_features': True,  # ìë™ íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                'prediction_features': ['Close']
            }

    def display(self, company_info, stock_info, market_data, analysis_results, history_df=None):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ íƒ­ í‘œì‹œ - ê°œì„ ëœ ì„¤ì • ì„¹ì…˜"""
        st.header("ğŸ“‘ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")

        # AI ì„¤ì • ì„¹ì…˜
        st.subheader("ğŸ› ï¸ AI ì„¤ì •")

        # AI ì„¤ì • í¼
        with st.form(key="ai_settings_form"):
            # 1. ì£¼ê°€ ì˜ˆì¸¡ ì„¤ì •
            st.markdown("### ì£¼ê°€ ì˜ˆì¸¡ ì„¤ì •")

            pred_col1, pred_col2, pred_col3 = st.columns(3)

            with pred_col1:
                # ëª¨ë¸ ìœ í˜• ì„¤ì • - í™•ì¥ëœ ëª¨ë¸ ì˜µì…˜
                model_options = ["LSTM", "Transformer", "ì•™ìƒë¸”", "TCN", "TFT", "N-BEATS", "Prophet", "í•˜ì´ë¸Œë¦¬ë“œ"]
                model_descriptions = {
                    "LSTM": "ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì í•©í•œ ê¸°ë³¸ ëª¨ë¸",
                    "Transformer": "ë³µì¡í•œ íŒ¨í„´ ì¸ì‹ì— ê°•í•œ ëª¨ë¸",
                    "ì•™ìƒë¸”": "LSTMê³¼ Transformer ëª¨ë¸ì„ ê²°í•©í•œ ëª¨ë¸",
                    "TCN": "ì‹œê°„ì  ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ì»¨ë³¼ë£¨ì…˜ ê¸°ë°˜ ëª¨ë¸",
                    "TFT": "ì‹œê°„ íŠ¹ì„±ì„ ê³ ë ¤í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸",
                    "N-BEATS": "ê³„ì¸µì  êµ¬ì¡°ì™€ ì—­íˆ¬ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•œ ëª¨ë¸",
                    "Prophet": "Facebookì˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ëª¨ë¸",
                    "í•˜ì´ë¸Œë¦¬ë“œ": "ëª¨ë“  ëª¨ë¸ì„ ê²°í•©í•œ ìµœì í™”ëœ ì•™ìƒë¸” ëª¨ë¸"
                }

                current_model = st.session_state.model_settings.get('model_type', 'LSTM')
                model_type = st.selectbox(
                    "ëª¨ë¸ ìœ í˜•",
                    options=model_options,
                    index=model_options.index(current_model) if current_model in model_options else 0,
                    help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸ ìœ í˜•ì„ ì„ íƒí•©ë‹ˆë‹¤.",
                    format_func=lambda x: f"{x} - {model_descriptions[x]}"
                )

            with pred_col2:
                # ì˜ˆì¸¡ ê¸°ê°„ ì„¤ì •
                prediction_days = st.slider(
                    "ì˜ˆì¸¡ ê¸°ê°„ (ì¼)",
                    min_value=30,
                    max_value=180,
                    value=st.session_state.model_settings.get('prediction_days', 60),
                    step=30,
                    help="ëª‡ ì¼ í›„ê¹Œì§€ ì˜ˆì¸¡í• ì§€ ì„¤ì •í•©ë‹ˆë‹¤."
                )

            with pred_col3:
                # Early Stopping Patience ì„¤ì • ì¶”ê°€
                patience = st.slider(
                    "Early Stopping Patience",
                    min_value=5,
                    max_value=30,
                    value=st.session_state.model_settings.get('patience', 20),
                    step=5,
                    help="ì„±ëŠ¥ ê°œì„ ì´ ì—†ì„ ë•Œ ëª‡ ë²ˆì˜ epochë¥¼ ë” ê¸°ë‹¤ë¦´ì§€ ì„¤ì •í•©ë‹ˆë‹¤."
                )

            # ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (íˆìŠ¤í† ë¦¬)
            history_years = st.slider(
                "ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„ (ë…„)",
                min_value=1,
                max_value=5,
                value=st.session_state.model_settings.get('history_years', 3),
                step=1,
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤."
            )

            # ì‹ ë¢°ë„ ì„¤ì • - ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ì‹ ì„ íƒ ë° ì‹ ë¢° ìˆ˜ì¤€
            confidence_col1, confidence_col2 = st.columns(2)

            with confidence_col1:
                use_monte_carlo = st.checkbox(
                    "ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ í™œì„±í™”",
                    value=st.session_state.model_settings.get('use_monte_carlo', True),
                    help="ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ë” ì •í™•í•œ ì‹ ë¢° êµ¬ê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
                )

            with confidence_col2:
                confidence_options = [0.8, 0.9, 0.95, 0.99]
                current_confidence = st.session_state.model_settings.get('confidence_level', 0.9)
                confidence_level = st.select_slider(
                    "ì‹ ë¢° ìˆ˜ì¤€",
                    options=confidence_options,
                    value=current_confidence if current_confidence in confidence_options else 0.9,
                    format_func=lambda x: f"{int(x * 100)}%",
                    help="ì˜ˆì¸¡ ì‹ ë¢° êµ¬ê°„ì˜ í™•ë¥ ì  ë²”ìœ„ì…ë‹ˆë‹¤."
                )

            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° - ì „ì²´ ì»¬ëŸ¼ í‘œê¸° (ê³ ê¸‰ ì„¤ì • ìœ„ë¡œ ì´ë™)
            if history_df is not None:
                with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    # ê¸°ë³¸ ë°ì´í„°
                    st.subheader("ê¸°ë³¸ ì£¼ê°€ ë°ì´í„°")
                    st.dataframe(history_df.tail(10))

                    # í™•ì¥ëœ ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„°
                    st.subheader("í™•ì¥ëœ ê¸°ìˆ ì  ì§€í‘œ")
                    # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° - ëª¨ë“  ì»¬ëŸ¼ í‘œì‹œ (ìˆ˜ì •)
                    from src.utils.stock_price_predictor import StockPricePredictor
                    predictor = StockPricePredictor()
                    extended_df = predictor._add_technical_indicators(history_df)
                    st.dataframe(extended_df.tail(10))

            # ìƒˆë¡œìš´ ê³ ê¸‰ ëª¨ë¸ì— ëŒ€í•œ ì¶”ê°€ ì„¤ì • ì„¹ì…˜
            self._display_enhanced_model_settings(model_type)

            # íŠ¹ì„± ì„ íƒ ì„¹ì…˜ (ê³ ê¸‰ ì„¤ì •)
            with st.expander("ê³ ê¸‰ ì„¤ì •", expanded=False):
                # ìë™ íŠ¹ì„± ì„ íƒ í™œì„±í™” ì—¬ë¶€
                use_auto_features = st.checkbox(
                    "ìë™ íŠ¹ì„± ì„ íƒ í™œì„±í™”",
                    value=st.session_state.model_settings.get('use_auto_features', True),
                    help="ìµœì ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ìœ„í•´ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤."
                )

                if not use_auto_features:
                    # ìˆ˜ë™ íŠ¹ì„± ì„ íƒ
                    feature_options = [
                        "Close", "Open", "High", "Low", "Volume",
                        "MA5", "MA10", "MA20", "MA60", "MA120",
                        "RSI", "MACD", "MACD_Signal", "MACD_Hist",
                        "BB_Middle", "BB_Upper", "BB_Lower", "BB_Width",
                        "Stoch_K", "Stoch_D", "ATR", "OBV",
                        "Price_Change_1D", "Price_Change_5D", "Price_Change_20D",
                        "Volume_Change_1D", "Volume_Change_5D", "Volume_Ratio"
                    ]

                    default_features = st.session_state.model_settings.get('prediction_features', ["Close"])
                    # ê¸°ë³¸ê°’ì´ feature_optionsì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    valid_defaults = [f for f in default_features if f in feature_options]
                    if not valid_defaults:
                        valid_defaults = ["Close"]

                    selected_features = st.multiselect(
                        "ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì„± ì„ íƒ",
                        options=feature_options,
                        default=valid_defaults,
                        help="ì£¼ê°€ ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì„±ì„ ì„ íƒí•©ë‹ˆë‹¤. 5ê°œ ë‚´ì™¸ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
                    )

                    # ì„ íƒëœ íŠ¹ì„±ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                    if not selected_features:
                        st.warning("íŠ¹ì„±ì„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ìë™ íŠ¹ì„± ì„ íƒì´ í™œì„±í™”ë©ë‹ˆë‹¤.")
                        selected_features = ["Auto"]
                        use_auto_features = True
                else:
                    selected_features = ["Auto"]

            # 2. ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •
            st.markdown("### ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •")

            # OpenAI API ì„¤ì •
            if self.openai_api_key is None:
                self.openai_api_key = st.text_input(
                    "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                    type="password",
                    help="AI ë¶„ì„ ìƒì„±ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤"
                )
            else:
                st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ë³€ê²½ì´ í•„ìš”í•˜ë©´ ì•„ë˜ì— ìƒˆ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.")
                new_key = st.text_input(
                    "OpenAI API í‚¤ ë³€ê²½ (í•„ìš”ì‹œ)",
                    type="password",
                    value="",
                    help="API í‚¤ë¥¼ ë³€ê²½í•˜ë ¤ë©´ ìƒˆ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”"
                )
                if new_key:
                    self.openai_api_key = new_key

            # LLM ëª¨ë¸ ì„¤ì •
            llm_col1, llm_col2, llm_col3 = st.columns(3)

            with llm_col1:
                model_options = ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"]
                current_model = st.session_state.report_options.get('llm_model', 'gpt-4o')
                model_index = 0  # ê¸°ë³¸ê°’
                if current_model in model_options:
                    model_index = model_options.index(current_model)

                model = st.selectbox(
                    "LLM ëª¨ë¸",
                    options=model_options,
                    index=model_index,
                    help="ë¶„ì„ì— ì‚¬ìš©í•  OpenAI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
                )

            with llm_col2:
                temperature = st.slider(
                    "Temperature",
                    min_value=0.0,
                    max_value=1.0,
                    value=st.session_state.report_options.get('temperature', 0.7),
                    step=0.1,
                    help="ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤."
                )

            with llm_col3:
                max_tokens = st.slider(
                    "ìµœëŒ€ í† í° ìˆ˜",
                    min_value=1000,
                    max_value=8000,
                    value=st.session_state.report_options.get('max_tokens', 2000),
                    step=500,
                    help="ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                )

            # ë¶„ì„ ê¹Šì´ ë° ì–¸ì–´ ì„¤ì •
            depth_lang_col1, depth_lang_col2 = st.columns(2)

            with depth_lang_col1:
                depth_options = ["ê¸°ë³¸", "ì‹¬í™”", "ì „ë¬¸ê°€"]
                default_depth = st.session_state.report_options.get('analysis_depth', 'ì‹¬í™”')
                # 'ê³ ê¸‰'ì´ ì•„ë‹Œ 'ì‹¬í™”'ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
                if default_depth not in depth_options:
                    default_depth = 'ì‹¬í™”'

                analysis_depth = st.radio(
                    "ë¶„ì„ ê¹Šì´",
                    options=depth_options,
                    index=depth_options.index(default_depth),
                    horizontal=True,
                    help="ìƒì„±ë  ë¶„ì„ ë³´ê³ ì„œì˜ ìƒì„¸ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                )

            with depth_lang_col2:
                lang_options = ["í•œêµ­ì–´", "ì˜ì–´"]
                default_lang = st.session_state.report_options.get('language', 'í•œêµ­ì–´')
                if default_lang not in lang_options:
                    default_lang = 'í•œêµ­ì–´'

                language = st.radio(
                    "ì–¸ì–´",
                    options=lang_options,
                    index=lang_options.index(default_lang),
                    horizontal=True,
                    help="ë³´ê³ ì„œ ìƒì„± ì–¸ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
                )

            # í¼ ì œì¶œ ë²„íŠ¼ (ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•¨)
            submit_button = st.form_submit_button("ì„¤ì • ì €ì¥")

            # ì„¤ì •ì´ ì €ì¥ë˜ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸
            if submit_button:
                # ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸
                st.session_state.model_settings.update({
                    'model_type': model_type,
                    'prediction_days': prediction_days,
                    'history_years': history_years,
                    'patience': patience,
                    'use_auto_features': use_auto_features,
                    'prediction_features': selected_features,
                    'use_monte_carlo': use_monte_carlo,
                    'confidence_level': confidence_level
                })

                # ì¶”ê°€ ëª¨ë¸ë³„ ì„¤ì • ì €ì¥
                if model_type == "TFT":
                    st.session_state.model_settings.update({
                        'tft_num_heads': st.session_state.model_settings.get('tft_num_heads', 4),
                        'tft_encoder_layers': st.session_state.model_settings.get('tft_encoder_layers', 2),
                        'tft_multiresolution': st.session_state.model_settings.get('tft_multiresolution', True)
                    })
                elif model_type == "TCN":
                    st.session_state.model_settings.update({
                        'tcn_kernel_size': st.session_state.model_settings.get('tcn_kernel_size', 3),
                        'tcn_filters': st.session_state.model_settings.get('tcn_filters', 64),
                        'tcn_layers': st.session_state.model_settings.get('tcn_layers', 4)
                    })
                elif model_type == "N-BEATS":
                    st.session_state.model_settings.update({
                        'nbeats_blocks': st.session_state.model_settings.get('nbeats_blocks', 3),
                        'nbeats_units': st.session_state.model_settings.get('nbeats_units', 128),
                        'nbeats_seasonal': st.session_state.model_settings.get('nbeats_seasonal', True)
                    })
                elif model_type == "í•˜ì´ë¸Œë¦¬ë“œ":
                    st.session_state.model_settings.update({
                        'use_prophet': st.session_state.model_settings.get('use_prophet', True),
                        'auto_weights': st.session_state.model_settings.get('auto_weights', True)
                    })

                # ë¦¬í¬íŠ¸ ì˜µì…˜ ì—…ë°ì´íŠ¸
                st.session_state.report_options.update({
                    'has_generated': st.session_state.report_options.get('has_generated', False),
                    'llm_model': model,
                    'temperature': temperature,
                    'max_tokens': max_tokens,
                    'analysis_depth': analysis_depth,
                    'language': language
                })

                st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # í¼ ì¢…ë£Œ í›„, í˜„ì¬ ì„¤ì • ì •ë³´ í‘œì‹œ
            st.subheader("ğŸ“‹ í˜„ì¬ ì„¤ì • ì •ë³´")

            # íƒ­ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì„¤ì • ì •ë³´ í‘œì‹œ
            tab1, tab2 = st.tabs(["ì£¼ê°€ ì˜ˆì¸¡ ì„¤ì •", "AI ë¶„ì„ ì„¤ì •"])

            with tab1:
                # ì£¼ê°€ ì˜ˆì¸¡ ì„¤ì • í‘œì‹œ
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("##### ê¸°ë³¸ ì„¤ì •")
                    st.markdown(f"""
                    - **ëª¨ë¸ ìœ í˜•**: {st.session_state.model_settings['model_type']}
                    - **ì˜ˆì¸¡ ê¸°ê°„**: {st.session_state.model_settings['prediction_days']}ì¼
                    - **ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„**: {st.session_state.model_settings.get('history_years', 3)}ë…„
                    - **Early Stopping Patience**: {st.session_state.model_settings.get('patience', 20)}
                    """)

                with col2:
                    st.markdown("##### ì‹ ë¢°ë„ ë° íŠ¹ì„± ì„¤ì •")

                    # ìë™ íŠ¹ì„± ì„ íƒ ì—¬ë¶€ì— ë”°ë¥¸ í‘œì‹œ
                    if st.session_state.model_settings.get('use_auto_features', True):
                        feature_info = "ìë™ íŠ¹ì„± ì„ íƒ í™œì„±í™”"
                    else:
                        feature_info = f"ìˆ˜ë™ ì„ íƒ: {', '.join(st.session_state.model_settings.get('prediction_features', ['Close']))}"

                    st.markdown(f"""
                    - **íŠ¹ì„± ì„ íƒ**: {feature_info}
                    - **ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜**: {'í™œì„±í™”' if st.session_state.model_settings.get('use_monte_carlo', True) else 'ë¹„í™œì„±í™”'}
                    - **ì‹ ë¢° ìˆ˜ì¤€**: {int(st.session_state.model_settings.get('confidence_level', 0.9) * 100)}%
                    """)

            with tab2:
                # AI ë¶„ì„ ì„¤ì • í‘œì‹œ
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("##### ëª¨ë¸ ì„¤ì •")
                    st.markdown(f"""
                    - **LLM ëª¨ë¸**: {st.session_state.report_options['llm_model']}
                    - **Temperature**: {st.session_state.report_options['temperature']}
                    - **ìµœëŒ€ í† í° ìˆ˜**: {st.session_state.report_options['max_tokens']}
                    """)

                with col2:
                    st.markdown("##### ì¶œë ¥ ì„¤ì •")
                    st.markdown(f"""
                    - **ë¶„ì„ ê¹Šì´**: {st.session_state.report_options['analysis_depth']}
                    - **ì–¸ì–´**: {st.session_state.report_options['language']}
                    - **ë¦¬í¬íŠ¸ ìƒì„± ì—¬ë¶€**: {'ì™„ë£Œ' if st.session_state.report_options.get('has_generated', False) else 'ë¯¸ìƒì„±'}
                    """)

            # API í‚¤ ìƒíƒœ í‘œì‹œ
            api_key_status = "ì„¤ì •ë¨ âœ…" if self.openai_api_key else "ë¯¸ì„¤ì • âŒ"
            st.markdown(f"**OpenAI API í‚¤ ìƒíƒœ**: {api_key_status}")

            # ë§ˆì§€ë§‰ ì„¤ì • ë³€ê²½ ì‹œê°„ í‘œì‹œ (ì˜µì…˜)
            if 'last_settings_update' not in st.session_state:
                st.session_state.last_settings_update = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            elif submit_button:
                st.session_state.last_settings_update = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            st.caption(f"ë§ˆì§€ë§‰ ì„¤ì • ë³€ê²½: {st.session_state.last_settings_update}")


        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ (í¼ ë°–ì— ìœ„ì¹˜)
        if st.button("ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±", help="AI ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ê³¼ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."):
            if not self.openai_api_key:
                st.error("AI ê¸°ë°˜ ë¶„ì„ì„ ìœ„í•´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return

            # ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            self._generate_comprehensive_report(
                company_info,
                stock_info,
                market_data,
                analysis_results,
                history_df
            )

    def _display_enhanced_model_settings(self, model_type):
        """í™•ì¥ëœ ëª¨ë¸ ìœ í˜•ì— ëŒ€í•œ ê³ ê¸‰ ì„¤ì • í‘œì‹œ"""
        # í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì„¤ì •
        if model_type == "í•˜ì´ë¸Œë¦¬ë“œ":
            st.write("#### ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì„¤ì •")
            st.info("í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸”ì€ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.")

            # Prophet ì‚¬ìš© ì—¬ë¶€
            use_prophet = st.checkbox(
                "Prophet ëª¨ë¸ í¬í•¨",
                value=st.session_state.model_settings.get('use_prophet', True),
                help="Facebookì˜ Prophet ëª¨ë¸ì„ ì•™ìƒë¸”ì— í¬í•¨í•©ë‹ˆë‹¤. ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            st.session_state.model_settings['use_prophet'] = use_prophet

            # ê°€ì¤‘ì¹˜ ìë™ ê³„ì‚° ì—¬ë¶€
            auto_weights = st.checkbox(
                "ê°€ì¤‘ì¹˜ ìë™ ê³„ì‚°",
                value=st.session_state.model_settings.get('auto_weights', True),
                help="ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤."
            )
            st.session_state.model_settings['auto_weights'] = auto_weights

            # ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì„¤ì •
            if not auto_weights:
                st.write("##### ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ ì„¤ì •")
                col1, col2, col3 = st.columns(3)

                with col1:
                    lstm_weight = st.slider(
                        "LSTM ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('lstm_weight', 0.3),
                        step=0.05
                    )
                    st.session_state.model_settings['lstm_weight'] = lstm_weight

                    tcn_weight = st.slider(
                        "TCN ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('tcn_weight', 0.2),
                        step=0.05
                    )
                    st.session_state.model_settings['tcn_weight'] = tcn_weight

                with col2:
                    transformer_weight = st.slider(
                        "Transformer ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('transformer_weight', 0.2),
                        step=0.05
                    )
                    st.session_state.model_settings['transformer_weight'] = transformer_weight

                    tft_weight = st.slider(
                        "TFT ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('tft_weight', 0.1),
                        step=0.05
                    )
                    st.session_state.model_settings['tft_weight'] = tft_weight

                with col3:
                    ensemble_weight = st.slider(
                        "ì•™ìƒë¸” ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('ensemble_weight', 0.1),
                        step=0.05
                    )
                    st.session_state.model_settings['ensemble_weight'] = ensemble_weight

                    prophet_weight = st.slider(
                        "Prophet ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.model_settings.get('prophet_weight', 0.1),
                        step=0.05
                    )
                    st.session_state.model_settings['prophet_weight'] = prophet_weight

                # ê°€ì¤‘ì¹˜ í•©ê³„ í™•ì¸ ë° ì •ê·œí™”
                total_weight = lstm_weight + transformer_weight + ensemble_weight + tcn_weight + tft_weight
                if use_prophet:
                    total_weight += prophet_weight

                # ê°€ì¤‘ì¹˜ í•©ê³„ê°€ 1ì„ ì´ˆê³¼í•˜ë©´ ê²½ê³ 
                if total_weight > 1.0:
                    st.warning(f"ê°€ì¤‘ì¹˜ í•©ê³„ê°€ 1ì„ ì´ˆê³¼í•©ë‹ˆë‹¤ ({total_weight:.2f}). ìë™ìœ¼ë¡œ ì •ê·œí™”ë©ë‹ˆë‹¤.")

        # TFT ëª¨ë¸ ì„¤ì •
        elif model_type == "TFT":
            st.write("#### ğŸ”„ Temporal Fusion Transformer ì„¤ì •")

            col1, col2 = st.columns(2)

            with col1:
                # ì–´í…ì…˜ í—¤ë“œ ìˆ˜
                num_heads = st.slider(
                    "ì–´í…ì…˜ í—¤ë“œ ìˆ˜",
                    min_value=1,
                    max_value=8,
                    value=st.session_state.model_settings.get('tft_num_heads', 4),
                    step=1,
                    help="ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì— ì‚¬ìš©í•  í—¤ë“œì˜ ìˆ˜ì…ë‹ˆë‹¤. ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ íŠ¹ì„± ê´€ê³„ë¥¼ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                st.session_state.model_settings['tft_num_heads'] = num_heads

            with col2:
                # ì¸ì½”ë” ë ˆì´ì–´ ìˆ˜
                encoder_layers = st.slider(
                    "ì¸ì½”ë” ë ˆì´ì–´ ìˆ˜",
                    min_value=1,
                    max_value=4,
                    value=st.session_state.model_settings.get('tft_encoder_layers', 2),
                    step=1,
                    help="íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” ë¸”ë¡ì˜ ìˆ˜ì…ë‹ˆë‹¤. ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë³µì¡í•œ íŒ¨í„´ì„ í¬ì°©í•  ìˆ˜ ìˆì§€ë§Œ í•™ìŠµì´ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤."
                )
                st.session_state.model_settings['tft_encoder_layers'] = encoder_layers

            # ë‹¤ì¤‘ í•´ìƒë„ ì²˜ë¦¬ í™œì„±í™”
            enable_multiresolution = st.checkbox(
                "ë‹¤ì¤‘ í•´ìƒë„ ì²˜ë¦¬ í™œì„±í™”",
                value=st.session_state.model_settings.get('tft_multiresolution', True),
                help="ì¼ë³„, ì£¼ë³„ ë“± ì—¬ëŸ¬ ì‹œê°„ í•´ìƒë„ì˜ íŒ¨í„´ì„ ë™ì‹œì— ê³ ë ¤í•©ë‹ˆë‹¤."
            )
            st.session_state.model_settings['tft_multiresolution'] = enable_multiresolution

        # TCN ëª¨ë¸ ì„¤ì •
        elif model_type == "TCN":
            st.write("#### ğŸ”„ Temporal Convolutional Network ì„¤ì •")

            col1, col2 = st.columns(2)

            with col1:
                # ì»¤ë„ í¬ê¸°
                kernel_size = st.select_slider(
                    "ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ í¬ê¸°",
                    options=[2, 3, 5, 7],
                    value=st.session_state.model_settings.get('tcn_kernel_size', 3),
                    help="ì»¨ë³¼ë£¨ì…˜ í•„í„°ì˜ í¬ê¸°ì…ë‹ˆë‹¤. í´ìˆ˜ë¡ ë” ë„“ì€ ì‹œê°„ ë²”ìœ„ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤."
                )
                st.session_state.model_settings['tcn_kernel_size'] = kernel_size

            with col2:
                # í•„í„° ìˆ˜
                num_filters = st.select_slider(
                    "í•„í„° ìˆ˜",
                    options=[32, 64, 128, 256],
                    value=st.session_state.model_settings.get('tcn_filters', 64),
                    help="ê° ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì˜ í•„í„° ìˆ˜ì…ë‹ˆë‹¤. ë§ì„ìˆ˜ë¡ ë³µì¡í•œ íŒ¨í„´ì„ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                st.session_state.model_settings['tcn_filters'] = num_filters

            # í™•ì¥ ë ˆì´ì–´ ìˆ˜
            num_layers = st.slider(
                "í™•ì¥ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ìˆ˜",
                min_value=2,
                max_value=8,
                value=st.session_state.model_settings.get('tcn_layers', 4),
                step=1,
                help="ë” ë§ì€ ë ˆì´ì–´ëŠ” ë” ê¸´ ì‹œê°„ ì˜ì¡´ì„±ì„ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            st.session_state.model_settings['tcn_layers'] = num_layers

        # N-BEATS ëª¨ë¸ ì„¤ì •
        elif model_type == "N-BEATS":
            st.write("#### ğŸ”„ N-BEATS ì„¤ì •")

            col1, col2 = st.columns(2)

            with col1:
                # ë¸”ë¡ ìˆ˜
                num_blocks = st.slider(
                    "ë¸”ë¡ ìˆ˜",
                    min_value=2,
                    max_value=6,
                    value=st.session_state.model_settings.get('nbeats_blocks', 3),
                    step=1,
                    help="N-BEATS ë¸”ë¡ ìˆ˜ì…ë‹ˆë‹¤. ë¸”ë¡ì´ ë§ì„ìˆ˜ë¡ ë³µì¡í•œ ì‹œê³„ì—´ êµ¬ì„±ìš”ì†Œë¥¼ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                st.session_state.model_settings['nbeats_blocks'] = num_blocks

            with col2:
                # íˆë“  ìœ ë‹› ìˆ˜
                hidden_units = st.select_slider(
                    "íˆë“  ìœ ë‹› ìˆ˜",
                    options=[64, 128, 256, 512],
                    value=st.session_state.model_settings.get('nbeats_units', 128),
                    help="ê° ë¸”ë¡ì˜ íˆë“  ë ˆì´ì–´ í¬ê¸°ì…ë‹ˆë‹¤."
                )
                st.session_state.model_settings['nbeats_units'] = hidden_units

            # ê³„ì ˆì„± ë¸”ë¡ ì¶”ê°€
            add_seasonal = st.checkbox(
                "ê³„ì ˆì„± ë¸”ë¡ ì¶”ê°€",
                value=st.session_state.model_settings.get('nbeats_seasonal', True),
                help="ì£¼ê¸°ì ì¸ íŒ¨í„´ì„ í¬ì°©í•˜ê¸° ìœ„í•œ íŠ¹ìˆ˜ ë¸”ë¡ì„ ì¶”ê°€í•©ë‹ˆë‹¤."
            )
            st.session_state.model_settings['nbeats_seasonal'] = add_seasonal

    def _generate_comprehensive_report(self, company_info, stock_info, market_data, analysis_results, history_df):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± í”„ë¡œì„¸ìŠ¤ - ìƒˆ ëª¨ë¸ ì§€ì› ì¶”ê°€"""
        try:
            with st.spinner("ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
                # í˜„ì¬ ê¸°ì—… ì‹ë³„ ì •ë³´ ì €ì¥
                current_company = company_info['symbol']

                # ì„¸ì…˜ ìƒíƒœì— í˜„ì¬ ê¸°ì—… ì •ë³´ ì €ì¥
                st.session_state.current_report_company = current_company

                # 1. ì£¼ê°€ ì˜ˆì¸¡ ì‹¤í–‰
                with st.spinner("ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰ ì¤‘..."):
                    st.info("ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
                    progress_bar = st.progress(0)

                    try:
                        # ë°ì´í„° ì¶©ë¶„ì„± í™•ì¸
                        MIN_REQUIRED_DATA = 60  # ìµœì†Œ 60ì¼ì¹˜ ë°ì´í„° í•„ìš”

                        if history_df is None or len(history_df) < MIN_REQUIRED_DATA:
                            error_msg = f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {MIN_REQUIRED_DATA}ì¼ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(history_df) if history_df is not None else 0}ì¼)"
                            st.error(error_msg)
                            logger.error(error_msg)

                            # ì´ì „ì— ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í˜„ì¬ íšŒì‚¬ ì •ë³´ì™€ ë¹„êµí•˜ì—¬ ì‚­ì œ
                            if ('prediction_result' in st.session_state.comprehensive_data and
                                    'current_prediction_symbol' in st.session_state and
                                    st.session_state.current_prediction_symbol != current_company):

                                # ì´ì „ ê¸°ì—…ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚­ì œ
                                logger.info(f"ì´ì „ ê¸°ì—…({st.session_state.current_prediction_symbol})ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì œê±°")
                                st.session_state.comprehensive_data['prediction_result'] = None

                                if 'model_evaluation' in st.session_state.comprehensive_data:
                                    st.session_state.comprehensive_data['model_evaluation'] = None

                            # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨)
                            default_prediction = {
                                'error': True,
                                'error_message': error_msg,
                                'company_symbol': current_company,
                                'dates': [],
                                'predicted': [],
                                'last_price': history_df['Close'].iloc[
                                    -1] if history_df is not None and not history_df.empty else 0,
                                'confidence_high': [],
                                'confidence_low': [],
                                'historical_volatility': 0,
                                'trend_strength': 0
                            }

                            # ì„¸ì…˜ ìƒíƒœì— ì˜ˆì¸¡ ì‹¤íŒ¨ ì •ë³´ ì €ì¥
                            st.session_state.comprehensive_data['prediction_result'] = default_prediction
                            st.session_state.comprehensive_data['prediction_status'] = 'failed'
                            st.session_state.current_prediction_symbol = current_company

                            progress_bar.empty()
                            raise ValueError(error_msg)

                        # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                        model_type = st.session_state.model_settings['model_type']

                        # ëª¨ë¸ ìœ í˜• ì •ê·œí™” - í•œê¸€/ì˜ë¬¸ ëª¨ë¸ëª… ì²˜ë¦¬
                        if model_type == "ì•™ìƒë¸”":
                            model_type = "ensemble"
                        elif model_type == "í•˜ì´ë¸Œë¦¬ë“œ":
                            model_type = "hybrid"

                        # ëª¨ë¸ ìœ í˜•ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
                        if model_type.lower() == "hybrid":
                            # í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì„¤ì • ì¶”ê°€
                            use_prophet = st.session_state.model_settings.get('use_prophet', True)
                            auto_weights = st.session_state.model_settings.get('auto_weights', True)

                            # í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì„¤ì • ë¡œê¹…
                            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì„¤ì • - Prophet ì‚¬ìš©: {use_prophet}, ìë™ ê°€ì¤‘ì¹˜: {auto_weights}")

                        elif model_type.upper() == "TFT":
                            # TFT ëª¨ë¸ íŠ¹ìˆ˜ ì„¤ì •
                            tft_num_heads = st.session_state.model_settings.get('tft_num_heads', 4)
                            tft_encoder_layers = st.session_state.model_settings.get('tft_encoder_layers', 2)
                            tft_multiresolution = st.session_state.model_settings.get('tft_multiresolution', True)

                            # TFT ì„¤ì • ë¡œê¹…
                            logger.info(
                                f"TFT ëª¨ë¸ ì„¤ì • - í—¤ë“œ: {tft_num_heads}, ë ˆì´ì–´: {tft_encoder_layers}, ë‹¤ì¤‘í•´ìƒë„: {tft_multiresolution}")

                        elif model_type.upper() == "TCN":
                            # TCN ëª¨ë¸ íŠ¹ìˆ˜ ì„¤ì •
                            tcn_kernel_size = st.session_state.model_settings.get('tcn_kernel_size', 3)
                            tcn_filters = st.session_state.model_settings.get('tcn_filters', 64)
                            tcn_layers = st.session_state.model_settings.get('tcn_layers', 4)

                            # TCN ì„¤ì • ë¡œê¹…
                            logger.info(f"TCN ëª¨ë¸ ì„¤ì • - ì»¤ë„: {tcn_kernel_size}, í•„í„°: {tcn_filters}, ë ˆì´ì–´: {tcn_layers}")

                        elif model_type.upper() == "N-BEATS":
                            # N-BEATS ëª¨ë¸ íŠ¹ìˆ˜ ì„¤ì •
                            nbeats_blocks = st.session_state.model_settings.get('nbeats_blocks', 3)
                            nbeats_units = st.session_state.model_settings.get('nbeats_units', 128)
                            nbeats_seasonal = st.session_state.model_settings.get('nbeats_seasonal', True)

                            # N-BEATS ì„¤ì • ë¡œê¹…
                            logger.info(
                                f"N-BEATS ëª¨ë¸ ì„¤ì • - ë¸”ë¡: {nbeats_blocks}, ìœ ë‹›: {nbeats_units}, ê³„ì ˆì„±: {nbeats_seasonal}")

                        # ì˜ˆì¸¡ ê¸°ê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                        forecast_days = st.session_state.model_settings['prediction_days']

                        # ìë™ íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
                        use_auto_features = st.session_state.model_settings.get('use_auto_features', True)

                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        if progress_bar:
                            progress_bar.progress(10, text="ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì„ íƒ ì¤‘...")

                        # íŠ¹ì„± ì„ íƒ
                        if use_auto_features:
                            # ìë™ íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
                            selected_features = self.price_predictor.auto_feature_selection(history_df)
                            st.info(f"ìë™ ì„ íƒëœ íŠ¹ì„±: {', '.join(selected_features)}")
                        else:
                            # ì‚¬ìš©ì ì„ íƒ íŠ¹ì„± ì‚¬ìš©
                            selected_features = st.session_state.model_settings['prediction_features']

                        # ë¡œê·¸ì— ì„¤ì •ê°’ ê¸°ë¡
                        logger.info(
                            f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤í–‰: ì‹¬ë³¼={company_info['symbol']}, ëª¨ë¸={model_type}, ì˜ˆì¸¡ê¸°ê°„={forecast_days}ì¼, íŠ¹ì„±={selected_features}")

                        if progress_bar:
                            progress_bar.progress(20, text="ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ ì¤‘...")

                        # ë¨¼ì € ëª¨ë¸ í•™ìŠµ
                        self.price_predictor.train_model(
                            history_df,
                            model_type=model_type,
                            forecast_days=forecast_days,
                            features=selected_features
                        )

                        if progress_bar:
                            progress_bar.progress(50, text="ëª¨ë¸ í•™ìŠµ ì™„ë£Œ, ì˜ˆì¸¡ ì¤‘...")

                        # ì˜ˆì¸¡ ì‹¤í–‰
                        prediction_result = self.price_predictor.predict_future(
                            history_df,
                            model_type=model_type,
                            days=forecast_days,
                            features=selected_features
                        )

                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        if progress_bar:
                            progress_bar.progress(100, text="ì˜ˆì¸¡ ì™„ë£Œ!")

                        if prediction_result:
                            # ëª¨ë¸ í‰ê°€ ì‹¤í–‰
                            model_evaluation = self.price_predictor.evaluate_model(
                                history_df,
                                model_type=model_type,
                                features=selected_features
                            )

                            # ìƒëŒ€ RMSE ê³„ì‚° ì¶”ê°€
                            if 'rmse' in model_evaluation:
                                last_price = history_df['Close'].iloc[-1]
                                model_evaluation['relative_rmse'] = (model_evaluation['rmse'] / last_price) * 100

                            # ì˜ˆì¸¡ ê²°ê³¼ì™€ ëª¨ë¸ í‰ê°€ ê²°ê³¼ ì €ì¥
                            st.session_state.comprehensive_data.update({
                                "prediction_result": prediction_result,
                                "model_evaluation": model_evaluation,
                                "selected_features": selected_features,
                                "history_df": history_df,  # íˆìŠ¤í† ë¦¬ ë°ì´í„°ë„ ì €ì¥í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ì‚¬ìš©
                                "prediction_status": 'completed',
                                "current_prediction_symbol": current_company,
                                "model_type": model_type  # ì‚¬ìš©ëœ ëª¨ë¸ íƒ€ì…ë„ ì €ì¥
                            })

                            st.success("ì£¼ê°€ ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                    except Exception as e:
                        st.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        logger.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
                        logger.error(traceback.format_exc())

                        # ì´ì „ì— ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í˜„ì¬ íšŒì‚¬ ì •ë³´ì™€ ë¹„êµí•˜ì—¬ ì‚­ì œ
                        if ('prediction_result' in st.session_state.comprehensive_data and
                                'current_prediction_symbol' in st.session_state and
                                st.session_state.current_prediction_symbol != current_company):

                            # ì´ì „ ê¸°ì—…ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚­ì œ
                            logger.info(f"ì´ì „ ê¸°ì—…({st.session_state.current_prediction_symbol})ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì œê±°")
                            st.session_state.comprehensive_data['prediction_result'] = None

                            if 'model_evaluation' in st.session_state.comprehensive_data:
                                st.session_state.comprehensive_data['model_evaluation'] = None

                        # í˜„ì¬ ê¸°ì—…ì— ëŒ€í•œ ì˜¤ë¥˜ ì •ë³´ë¥¼ ë‹´ì€ ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
                        error_message = str(e)
                        default_prediction = {
                            'error': True,
                            'error_message': error_message,
                            'company_symbol': current_company,
                            'dates': [],
                            'predicted': [],
                            'last_price': history_df['Close'].iloc[
                                -1] if history_df is not None and not history_df.empty else 0,
                            'confidence_high': [],
                            'confidence_low': [],
                            'historical_volatility': 0,
                            'trend_strength': 0
                        }

                        # ì„¸ì…˜ ìƒíƒœì— ì˜ˆì¸¡ ì‹¤íŒ¨ ì •ë³´ ì €ì¥
                        st.session_state.comprehensive_data['prediction_result'] = default_prediction
                        st.session_state.comprehensive_data['prediction_status'] = 'failed'
                        st.session_state.current_prediction_symbol = current_company

                    finally:
                        progress_bar.empty()

                # 2. LLM ë¶„ì„ ìƒì„±
                try:
                    comprehensive_data = self.get_comprehensive_data(
                        company_info, stock_info, market_data, analysis_results, history_df
                    )

                    # ì˜ˆì¸¡ ë° í‰ê°€ ê²°ê³¼ ì¶”ê°€
                    if 'prediction_result' in st.session_state.comprehensive_data:
                        comprehensive_data['prediction_result'] = st.session_state.comprehensive_data[
                            'prediction_result']

                        # ìƒˆë¡œìš´ ëª¨ë¸ì— ëŒ€í•œ ì •ë³´ ì¶”ê°€
                        model_type = st.session_state.comprehensive_data.get('model_type', 'LSTM')
                        comprehensive_data['model_type'] = model_type

                        # íŠ¹í™” ëª¨ë¸ ì„¤ì • ì •ë³´ ì¶”ê°€
                        if model_type.lower() == "hybrid":
                            comprehensive_data['hybrid_settings'] = {
                                'use_prophet': st.session_state.model_settings.get('use_prophet', True),
                                'auto_weights': st.session_state.model_settings.get('auto_weights', True)
                            }
                        elif model_type.upper() == "TFT":
                            comprehensive_data['tft_settings'] = {
                                'num_heads': st.session_state.model_settings.get('tft_num_heads', 4),
                                'encoder_layers': st.session_state.model_settings.get('tft_encoder_layers', 2),
                                'multiresolution': st.session_state.model_settings.get('tft_multiresolution', True)
                            }
                        elif model_type.upper() == "TCN":
                            comprehensive_data['tcn_settings'] = {
                                'kernel_size': st.session_state.model_settings.get('tcn_kernel_size', 3),
                                'filters': st.session_state.model_settings.get('tcn_filters', 64),
                                'layers': st.session_state.model_settings.get('tcn_layers', 4)
                            }
                        elif model_type.upper() == "N-BEATS":
                            comprehensive_data['nbeats_settings'] = {
                                'blocks': st.session_state.model_settings.get('nbeats_blocks', 3),
                                'units': st.session_state.model_settings.get('nbeats_units', 128),
                                'seasonal': st.session_state.model_settings.get('nbeats_seasonal', True)
                            }

                    if 'model_evaluation' in st.session_state.comprehensive_data:
                        comprehensive_data['model_evaluation'] = st.session_state.comprehensive_data['model_evaluation']
                    if 'history_df' in st.session_state.comprehensive_data:
                        comprehensive_data['history_df'] = st.session_state.comprehensive_data['history_df']

                    llm_data = self.prepare_llm_data(comprehensive_data, "comprehensive")

                    ai_analysis = self.generate_ai_analysis(
                        llm_data,
                        st.session_state.report_options['language'],
                        None,
                        st.session_state.report_options['llm_model'],
                        st.session_state.report_options['temperature'],
                        st.session_state.report_options['max_tokens'],
                        analysis_depth=st.session_state.report_options['analysis_depth']
                    )
                    comprehensive_data["ai_analysis"] = ai_analysis

                except Exception as e:
                    st.error(f"AI ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    logger.error(f"AI ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                    logger.error(traceback.format_exc())

                # 3. í†µí•© ë¦¬í¬íŠ¸ í‘œì‹œ
                self._display_unified_report(
                    comprehensive_data,
                    "AI ê¸°ë°˜ ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸",
                    "í•œêµ­ì–´",
                    company_info,
                    True
                )

        except Exception as e:
            st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())
            
    def generate_dynamic_prompt(self, llm_data, language="í•œêµ­ì–´", analysis_focus=None, analysis_depth="ì‹¬í™”"):
        """ë°ì´í„°ì— ê¸°ë°˜í•œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ì–¸ì–´ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
        if language == "ì˜ì–´":
            prompt_template = f"""
            You are a securities research analyst tasked with creating a comprehensive analysis report for {llm_data['company']['name']}({llm_data['company']['symbol']}).
            Please provide useful insights for investors based on various analysis results.
            """

            # ë¶„ì„ ê¹Šì´ì— ë”°ë¥¸ ì˜ì–´ ì§€ì‹œì‚¬í•­
            if analysis_depth == "ê¸°ë³¸":
                prompt_template += """
                # Analysis Depth
                Provide concise and essential information only. Focus on the most important points that investors can quickly understand.
                """
            elif analysis_depth == "ì „ë¬¸ê°€":
                prompt_template += """
                # Analysis Depth
                Provide expert-level in-depth analysis and advanced investment strategies. Include professional content such as market microstructure, 
                advanced aspects of technical analysis, and analysis linked to portfolio theory.
                """
            else:  # "ì‹¬í™”" ê¸°ë³¸ê°’
                prompt_template += """
                # Analysis Depth
                Provide balanced analysis and practical investment insights. Balance fundamental and technical analysis, 
                and include in-depth consideration of possible investment scenarios.
                """

            prompt_template += """
            # Key Analysis Data
            """
        else:  # ê¸°ë³¸ê°’: í•œêµ­ì–´
            prompt_template = f"""
            ë‹¹ì‹ ì€ ì¦ê¶Œì‚¬ì˜ ë¦¬ì„œì¹˜ ì• ë„ë¦¬ìŠ¤íŠ¸ë¡œ, {llm_data['company']['name']}({llm_data['company']['symbol']})ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
            ë‹¤ì–‘í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ììì—ê²Œ ìœ ìš©í•œ ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
            """

            # ë¶„ì„ ê¹Šì´ì— ë”°ë¥¸ í•œêµ­ì–´ ì§€ì‹œì‚¬í•­
            if analysis_depth == "ê¸°ë³¸":
                prompt_template += """
                # ë¶„ì„ ê¹Šì´
                ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ì •ë³´ë§Œ ì œê³µí•´ì£¼ì„¸ìš”. íˆ¬ììê°€ ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ë‹¤ë£¨ì„¸ìš”.
                """
            elif analysis_depth == "ì „ë¬¸ê°€":
                prompt_template += """
                # ë¶„ì„ ê¹Šì´
                ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê¹Šì´ ìˆëŠ” ë¶„ì„ê³¼ ê³ ê¸‰ íˆ¬ì ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”. ì‹œì¥ ë¯¸ì‹œêµ¬ì¡°, ê¸°ìˆ ì  ë¶„ì„ì˜ ê³ ê¸‰ ì¸¡ë©´, 
                í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¡ ê³¼ ì—°ê³„í•œ ë¶„ì„ ë“± ì „ë¬¸ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
                """
            else:  # "ì‹¬í™”" ê¸°ë³¸ê°’
                prompt_template += """
                # ë¶„ì„ ê¹Šì´
                ê· í˜• ì¡íŒ ë¶„ì„ê³¼ ì‹¤ìš©ì ì¸ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. ê¸°ë³¸ì  ë¶„ì„ê³¼ ê¸°ìˆ ì  ë¶„ì„ì˜ ê· í˜•ì„ ë§ì¶”ê³ ,
                ê°€ëŠ¥í•œ íˆ¬ì ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ê³ ë ¤ë¥¼ í¬í•¨í•˜ì„¸ìš”.
                """

            prompt_template += """
            # ì£¼ìš” ë¶„ì„ ë°ì´í„°
            """

        # ë¶„ì„ ë°ì´í„° ì„¹ì…˜ êµ¬ì„± - ì–¸ì–´ì— ë§ê²Œ ì„¹ì…˜ ì œëª© ì¡°ì •
        sections = []

        # ê¸°ìˆ ì  ë¶„ì„ ì„¹ì…˜
        if 'technical_analysis' in llm_data:
            if language == "ì˜ì–´":
                tech_section = "## Technical Analysis\n"
            else:
                tech_section = "## ê¸°ìˆ ì  ë¶„ì„\n"

            for key, value in llm_data['technical_analysis'].items():
                tech_section += f"- {key}: {value}\n"
            sections.append(tech_section)

        # íˆ¬ìì ë™í–¥ ì„¹ì…˜
        if 'investor_trends' in llm_data:
            if language == "ì˜ì–´":
                investor_section = "## Investor Trends\n"
            else:
                investor_section = "## íˆ¬ìì ë™í–¥\n"

            for key, value in llm_data['investor_trends'].items():
                # investor_ratioëŠ” ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ íŠ¹ë³„íˆ ì²˜ë¦¬
                if key == 'investor_ratio' and isinstance(value, list) and len(value) >= 4:
                    if language == "ì˜ì–´":
                        investor_section += f"- Institutional investors: {value[0]}%\n"
                        investor_section += f"- Foreign investors: {value[1]}%\n"
                        investor_section += f"- Individual investors: {value[2]}%\n"
                        investor_section += f"- Other corporations: {value[3]}%\n"
                    else:
                        investor_section += f"- ê¸°ê´€íˆ¬ìì ë¹„ì¤‘: {value[0]}%\n"
                        investor_section += f"- ì™¸êµ­ì¸ ë¹„ì¤‘: {value[1]}%\n"
                        investor_section += f"- ê°œì¸ ë¹„ì¤‘: {value[2]}%\n"
                        investor_section += f"- ê¸°íƒ€ë²•ì¸ ë¹„ì¤‘: {value[3]}%\n"
                else:
                    investor_section += f"- {key}: {value}\n"
            sections.append(investor_section)

        # ìœ„í—˜ ì§€í‘œ ì„¹ì…˜
        if 'financial_analysis' in llm_data and 'risk_metrics' in llm_data['financial_analysis']:
            if language == "ì˜ì–´":
                risk_section = "## Risk Metrics\n"
            else:
                risk_section = "## ìœ„í—˜ ì§€í‘œ\n"

            for key, value in llm_data['financial_analysis']['risk_metrics'].items():
                risk_section += f"- {key}: {value}\n"
            sections.append(risk_section)

        # ë§¤ë§¤ ì‹ í˜¸ ì„¹ì…˜
        if 'trading_signals' in llm_data:
            if language == "ì˜ì–´":
                signal_section = "## Optimal Trading Points\n"
            else:
                signal_section = "## ìµœì  ë§¤ë§¤ ì‹œì \n"

            for key, value in llm_data['trading_signals'].items():
                if not isinstance(value, list) and not isinstance(value, dict):
                    signal_section += f"- {key}: {value}\n"
            sections.append(signal_section)

        # ì£¼ê°€ ì˜ˆì¸¡ ì„¹ì…˜
        if 'prediction_result' in llm_data:
            if language == "ì˜ì–´":
                prediction_section = "## Stock Price Prediction\n"
            else:
                prediction_section = "## ì£¼ê°€ ì˜ˆì¸¡\n"

            pred_data = llm_data['prediction_result']

            # ê¸°ë³¸ ì˜ˆì¸¡ ì •ë³´
            prediction_section += f"- last_price: {pred_data.get('last_price', 0)}\n"
            prediction_section += f"- final_prediction: {pred_data.get('final_prediction', 0)}\n"
            prediction_section += f"- overall_change_percent: {pred_data.get('overall_change_percent', 0)}%\n"
            prediction_section += f"- prediction_days: {pred_data.get('prediction_days', 0)}\n"

            # ê¸°ê°„ë³„ ì˜ˆì¸¡ ì •ë³´
            for period in ['short_term', 'mid_term', 'long_term']:
                if period in pred_data:
                    prediction_section += f"- {period}:\n"
                    for key, value in pred_data[period].items():
                        prediction_section += f"  - {key}: {value}\n"

            sections.append(prediction_section)

        # ë¶„ì„ ì´ˆì ì´ ìˆëŠ” ê²½ìš° ê´€ë ¨ ì˜ì—­ ê°•ì¡°
        if analysis_focus:
            if language == "ì˜ì–´":
                prompt_template += f"\n# Analysis Focus\nPlease focus especially on {analysis_focus} in your analysis.\n"
            else:
                prompt_template += f"\n# ë¶„ì„ ì´ˆì \níŠ¹íˆ {analysis_focus}ì— ì¤‘ì ì„ ë‘ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.\n"

        # ëª¨ë“  ì„¹ì…˜ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        prompt_template += "\n".join(sections)

        # ìš”ì²­ì‚¬í•­ ì¶”ê°€
        if language == "ì˜ì–´":
            prompt_template += """

            # Requirements
            1. Please provide useful insights to investors by comprehensively analyzing the above data.
            2. Include a SWOT analysis (Strengths, Weaknesses, Opportunities, Threats).
            3. Present short-term (1-3 months) and medium-term (6-12 months) outlooks.
            4. Suggest 2-3 action plans that will be helpful to investors.
            5. Present an overall investment opinion (Buy/Sell/Hold) and explain the reasons.

            # Format
            - Please write in markdown format.
            - Keep the response length around 1000 words.
            - Structure with titles and subtitles.
            - Use professional terminology but explain at a level that general investors can understand.
            """
        else:
            prompt_template += """

            # ìš”ì²­ì‚¬í•­
            1. ìœ„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ íˆ¬ììì—ê²Œ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
            2. SWOT ë¶„ì„ì„ í¬í•¨í•´ì£¼ì„¸ìš”. (ê°•ì , ì•½ì , ê¸°íšŒ, ìœ„í˜‘)
            3. ë‹¨ê¸°(1-3ê°œì›”), ì¤‘ê¸°(6-12ê°œì›”) ì „ë§ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
            4. íˆ¬ììì—ê²Œ ë„ì›€ì´ ë  ë§Œí•œ ì•¡ì…˜ í”Œëœì„ 2-3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
            5. ì „ì²´ì ì¸ íˆ¬ì ì˜ê²¬(ë§¤ìˆ˜/ë§¤ë„/ê´€ë§)ì„ ì œì‹œí•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

            # í˜•ì‹
            - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            - ì‘ë‹µ ê¸¸ì´ëŠ” 1000ë‹¨ì–´ ë‚´ì™¸ë¡œ í•´ì£¼ì„¸ìš”.
            - ì œëª©ê³¼ ì†Œì œëª©ì„ í¬í•¨í•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            - ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜ ì¼ë°˜ íˆ¬ììë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """

        return prompt_template

    def _run_stock_prediction(self, symbol, stock_data, progress_bar=None):
        """ì£¼ê°€ ì˜ˆì¸¡ ì‹¤í–‰ - ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬"""
        try:
            # ë°ì´í„° ì¶©ë¶„ì„± í™•ì¸
            MIN_REQUIRED_DATA = 60  # ìµœì†Œ 60ì¼ì¹˜ ë°ì´í„° í•„ìš”
            if len(stock_data) < MIN_REQUIRED_DATA:
                error_msg = f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {MIN_REQUIRED_DATA}ì¼ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(stock_data)}ì¼)"
                if progress_bar:
                    progress_bar.error(error_msg)
                logger.error(error_msg)

                # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨)
                default_prediction = {
                    'error': True,
                    'error_message': error_msg,
                    'dates': [],
                    'predicted': [],
                    'last_price': stock_data['Close'].iloc[-1] if not stock_data.empty else 0,
                    'confidence_high': [],
                    'confidence_low': [],
                    'historical_volatility': 0,
                    'trend_strength': 0
                }
                return default_prediction

            # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            model_type = st.session_state.model_settings.get('model_type', 'LSTM').lower()
            if model_type == "ì•™ìƒë¸”":
                model_type = "ensemble"

            # ì˜ˆì¸¡ ê¸°ê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            forecast_days = st.session_state.model_settings.get('prediction_days', 30)

            # ë¡œê·¸ì— ì„¤ì •ê°’ ê¸°ë¡
            logger.info(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤í–‰: ì‹¬ë³¼={symbol}, ëª¨ë¸={model_type}, ì˜ˆì¸¡ê¸°ê°„={forecast_days}ì¼")

            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if progress_bar:
                progress_bar.progress(10, text="ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")

            try:
                # ë¨¼ì € ëª¨ë¸ í•™ìŠµ
                train_success = self.price_predictor.train_model(
                    stock_data,
                    model_type=model_type,
                    forecast_days=forecast_days
                )

                if not train_success:
                    raise ValueError("ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                if progress_bar:
                    progress_bar.progress(50, text="ëª¨ë¸ í•™ìŠµ ì™„ë£Œ, ì˜ˆì¸¡ ì¤‘...")

                # ì˜ˆì¸¡ ì‹¤í–‰
                prediction_result = self.price_predictor.predict_future(
                    stock_data,
                    model_type=model_type,
                    days=forecast_days
                )

                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if progress_bar:
                    progress_bar.progress(100, text="ì˜ˆì¸¡ ì™„ë£Œ!")

                return prediction_result

            except Exception as inner_e:
                error_msg = str(inner_e)
                logger.error(f"ì˜ˆì¸¡ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {error_msg}")
                import traceback
                logger.error(traceback.format_exc())

                # ì˜¤ë¥˜ ë©”ì‹œì§€ ë¶„ë¥˜
                if 'tuple index out of range' in error_msg:
                    friendly_error = "ë°ì´í„° ë¶€ì¡± ë˜ëŠ” í˜•ì‹ì´ ë§ì§€ ì•Šì•„ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                elif 'ë¶€ì¡±' in error_msg or 'insufficient' in error_msg.lower():
                    friendly_error = f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ê¸´ ê¸°ê°„ì˜ ì£¼ê°€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                else:
                    friendly_error = f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"

                if progress_bar:
                    progress_bar.error(friendly_error)

                # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨)
                default_prediction = {
                    'error': True,
                    'error_message': friendly_error,
                    'dates': [],
                    'predicted': [],
                    'last_price': stock_data['Close'].iloc[-1] if not stock_data.empty else 0,
                    'confidence_high': [],
                    'confidence_low': [],
                    'historical_volatility': 0,
                    'trend_strength': 0
                }
                return default_prediction

        except Exception as e:
            logger.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            if progress_bar:
                progress_bar.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                progress_bar.empty()

            # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨)
            default_prediction = {
                'error': True,
                'error_message': f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                'dates': [],
                'predicted': [],
                'last_price': stock_data['Close'].iloc[-1] if isinstance(stock_data,
                                                                         pd.DataFrame) and not stock_data.empty else 0,
                'confidence_high': [],
                'confidence_low': [],
                'historical_volatility': 0,
                'trend_strength': 0
            }
            return default_prediction

    def register_analysis_result(self, tab_name, data):
        """ê° íƒ­ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë“±ë¡"""
        if 'comprehensive_data' not in st.session_state:
            self._initialize_data_store()

        # ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì¸ ê²½ìš° ì²˜ë¦¬
        if tab_name == 'financial_analysis' and isinstance(data, dict):
            for key, value in data.items():
                if key in st.session_state.comprehensive_data['financial_analysis']:
                    st.session_state.comprehensive_data['financial_analysis'][key] = value
        else:
            st.session_state.comprehensive_data[tab_name] = data

        # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ ê¸°ë¡
        st.session_state.comprehensive_data['last_update'][tab_name] = datetime.now().isoformat()

        # ìºì‹œ ë¬´íš¨í™”
        st.session_state.comprehensive_data['analysis_cache'] = {}

        logger.info(f"íƒ­ '{tab_name}' ë¶„ì„ ê²°ê³¼ê°€ ì¢…í•© ë°ì´í„°ì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def get_comprehensive_data(self, company_info, stock_info, market_data, analysis_results, history_df=None):
        """ì™„ì „í•œ ì¢…í•© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        # ë°ì´í„° ì €ì¥ì†Œ ì´ˆê¸°í™” í™•ì¸
        if 'comprehensive_data' not in st.session_state:
            self._initialize_data_store()

        # ê¸°ë³¸ ì •ë³´ ì—…ë°ì´íŠ¸
        comprehensive_data = st.session_state.comprehensive_data.copy()
        comprehensive_data['company_info'] = company_info
        comprehensive_data['stock_info'] = stock_info
        comprehensive_data['market_data'] = market_data
        comprehensive_data['analysis_results'] = analysis_results
        comprehensive_data['history_df'] = history_df

        # ëˆ„ë½ëœ ë°ì´í„° í™•ì¸ ë° í•„ìš”ì‹œ ìˆ˜ì§‘
        self._ensure_essential_data(comprehensive_data)

        return comprehensive_data

    def _ensure_essential_data(self, data):
        """í•„ìˆ˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì • ë˜ëŠ” ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        # ê¸°ë³¸ ì£¼ì‹ ìƒì„¸ ì •ë³´ í™•ì¸
        if not data.get('stock_detail'):
            data['stock_detail'] = self._extract_stock_detail(data)

        # ê¸°ë³¸ ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° í™•ì¸
        if not data.get('technical_analysis'):
            data['technical_analysis'] = self._extract_technical_analysis(data)

        # ê¸°ë³¸ íˆ¬ìì ë™í–¥ ë°ì´í„° í™•ì¸
        if not data.get('investor_trends'):
            data['investor_trends'] = self._extract_investor_trends(data)

        # ìœ„í—˜ ì§€í‘œ í™•ì¸ - ì„¸ì…˜ ìƒíƒœì—ì„œë„ í™•ì¸
        if not data.get('financial_analysis', {}).get('risk_metrics') and 'risk_metrics' in st.session_state:
            if 'financial_analysis' not in data:
                data['financial_analysis'] = {}
            data['financial_analysis']['risk_metrics'] = st.session_state.risk_metrics

        # ì„±ì¥ë¥  ë°ì´í„° í™•ì¸ - ì„¸ì…˜ ìƒíƒœì—ì„œë„ í™•ì¸
        if not data.get('financial_analysis', {}).get('growth_data') and 'growth_data' in st.session_state:
            if 'financial_analysis' not in data:
                data['financial_analysis'] = {}
            data['financial_analysis']['growth_data'] = st.session_state.growth_data

        # ë§¤ë§¤ ì‹ í˜¸ ë°ì´í„° í™•ì¸ - ì„¸ì…˜ ìƒíƒœì—ì„œë„ í™•ì¸
        if not data.get('trading_signals') and 'trading_signals' in st.session_state:
            data['trading_signals'] = st.session_state.trading_signals

        # ì£¼ê°€ ì˜ˆì¸¡ ë°ì´í„° í™•ì¸ - ì„¸ì…˜ ìƒíƒœì—ì„œë„ í™•ì¸
        if not data.get('prediction_result') and 'prediction_result' in st.session_state and st.session_state.get(
                'prediction_status') == 'completed':
            data['prediction_result'] = st.session_state.prediction_result

        # ê²°ì¸¡ ë°ì´í„° ê¸°ë³¸ê°’ ì„¤ì •
        if not data.get('financial_analysis', {}).get('risk_metrics'):
            if 'financial_analysis' not in data:
                data['financial_analysis'] = {}
            data['financial_analysis']['risk_metrics'] = {
                "beta": 1.0,
                "annual_volatility": 15.0,
                "max_drawdown": 20.0,
                "sharpe_ratio": 0.5
            }

        if not data.get('financial_analysis', {}).get('growth_data'):
            if 'financial_analysis' not in data:
                data['financial_analysis'] = {}
            data['financial_analysis']['growth_data'] = {
                "annual": {
                    "revenue_growth": [],
                    "operating_income_growth": [],
                    "net_income_growth": []
                }
            }

        if not data.get('trading_signals'):
            data['trading_signals'] = {
                "recommendation": "ê´€ë§",
                "current_buy_strength": 0,
                "current_sell_strength": 0,
                "latest_buy": [{"ë‚ ì§œ": "N/A", "ê·¼ê±°": "N/A"}],
                "latest_sell": [{"ë‚ ì§œ": "N/A", "ê·¼ê±°": "N/A"}]
            }

    def _extract_stock_detail(self, data):
        """ë§ˆì¼“ ë°ì´í„°ì—ì„œ ì£¼ì‹ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        market_data = data.get('market_data', {})
        stock_info = data.get('stock_info', {})

        return {
            "current_price": market_data.get('close', [])[-1] if market_data.get('close') and len(
                market_data.get('close', [])) > 0 else 0,
            "price_change": ((market_data.get('close', [])[-1] - market_data.get('close', [])[-2]) /
                             market_data.get('close', [])[-2]) * 100
            if market_data.get('close') and len(market_data.get('close', [])) >= 2 else 0,
            "volume": market_data.get('volume', [])[-1] if market_data.get('volume') and len(
                market_data.get('volume', [])) > 0 else 0,
            "market_cap": getattr(stock_info, 'market_cap', 0) or 0
        }

    def _extract_technical_analysis(self, data):
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ê¸°ìˆ ì  ë¶„ì„ ì •ë³´ ì¶”ì¶œ"""
        analysis_results = data.get('analysis_results', {})

        return {
            "trend": analysis_results.get('trend', 'N/A'),
            "ma5": analysis_results.get('ma5', 0),
            "ma20": analysis_results.get('ma20', 0),
            "rsi": analysis_results.get('rsi', 0),
            "rsi_status": analysis_results.get('rsi_status', 'N/A'),
            "volume_trend": analysis_results.get('volume_trend', 'N/A')
        }

    def _extract_investor_trends(self, data):
        """ë¶„ì„ ê²°ê³¼ì—ì„œ íˆ¬ìì ë™í–¥ ì •ë³´ ì¶”ì¶œ"""
        analysis_results = data.get('analysis_results', {})
        market_data = data.get('market_data', {})

        return {
            "main_buyer": analysis_results.get('main_buyer', 'N/A'),
            "main_seller": analysis_results.get('main_seller', 'N/A'),
            "investor_ratio": market_data.get('investor_ratio', [0, 0, 0, 0])
        }

    def prepare_llm_data(self, report_data, detail_level="comprehensive"):
        """LLM ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        # comprehensive ê³ ì •ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ë‹¤ë¥¸ ì¡°ê±´ ì‚­ì œ
        # ê°€ëŠ¥í•œ ëª¨ë“  ë°ì´í„° í¬í•¨ (ë‹¨, ë„ˆë¬´ í¬ê±°ë‚˜ ë³µì¡í•œ ë°ì´í„°ëŠ” ì œì™¸)
        llm_data = {
            "company": report_data["company_info"],
            "stock_detail": report_data["stock_detail"],
            "technical_analysis": report_data["technical_analysis"],
            "investor_trends": report_data["investor_trends"],
            "financial_analysis": report_data["financial_analysis"],
            "trading_signals": report_data["trading_signals"]
        }

        # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í¬í•¨
        if report_data.get("prediction_result"):
            llm_data["prediction_result"] = self._format_prediction_data(report_data["prediction_result"])

        # íˆìŠ¤í† ë¦¬ ë°ì´í„°ëŠ” ë„ˆë¬´ í¬ë¯€ë¡œ ì œì™¸
        if "history_df" in llm_data:
            del llm_data["history_df"]

        return llm_data

    def _format_prediction_data(self, prediction_result):
        """ì˜ˆì¸¡ ë°ì´í„° í¬ë§·íŒ…"""
        if not prediction_result:
            return None

        # NumPy ë°°ì—´ ì²˜ë¦¬
        predicted = prediction_result.get('predicted', [])
        if isinstance(predicted, np.ndarray):
            predicted = predicted.tolist()
        elif isinstance(predicted, pd.Series):
            predicted = predicted.values.tolist()

        last_price = prediction_result.get('last_price', 0)

        # ê¸°ê°„ë³„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        short_term = predicted[:7] if len(predicted) >= 7 else predicted
        mid_term = predicted[7:21] if len(predicted) >= 21 else predicted[7:] if len(predicted) >= 7 else []
        long_term = predicted[21:] if len(predicted) >= 21 else []

        # ê¸°ê°„ë³„ ë³€í™”ìœ¨ ê³„ì‚°
        short_term_change = ((short_term[-1] - last_price) / last_price * 100) if short_term else 0
        mid_term_change = ((mid_term[-1] - last_price) / last_price * 100) if mid_term else 0
        long_term_change = ((long_term[-1] - last_price) / last_price * 100) if long_term else 0

        return {
            "last_price": last_price,
            "predicted": predicted,
            "prediction_days": len(predicted),
            "final_prediction": predicted[-1] if predicted else 0,
            "overall_change_percent": ((predicted[-1] - last_price) / last_price * 100) if predicted else 0,
            "short_term": {
                "period": "7ì¼",
                "change_percent": short_term_change,
                "trend": "ìƒìŠ¹" if short_term_change > 0 else "í•˜ë½"
            },
            "mid_term": {
                "period": "7-21ì¼",
                "change_percent": mid_term_change,
                "trend": "ìƒìŠ¹" if mid_term_change > 0 else "í•˜ë½" if mid_term_change < 0 else "ë°ì´í„° ì—†ìŒ"
            },
            "long_term": {
                "period": "21ì¼ ì´ìƒ",
                "change_percent": long_term_change,
                "trend": "ìƒìŠ¹" if long_term_change > 0 else "í•˜ë½" if long_term_change < 0 else "ë°ì´í„° ì—†ìŒ"
            }
        }

    def generate_ai_analysis(self, llm_data, language="í•œêµ­ì–´", analysis_focus=None,
                             model="gpt-4o", temperature=0.7, max_tokens=2000,
                             analysis_depth="ì‹¬í™”"):
        """LLM ê¸°ë°˜ AI ë¶„ì„ ìƒì„±"""
        try:
            # ìºì‹œ í‚¤ ìƒì„± (ëª¨ë¸, ì˜¨ë„, í† í° ìˆ˜ í¬í•¨)
            cache_key = f"{language}_{analysis_focus}_{model}_{temperature}_{max_tokens}_{analysis_depth}_{hash(json.dumps(llm_data, sort_keys=True, default=str))}"

            # ìºì‹œëœ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
            cached_analysis = st.session_state.comprehensive_data.get('analysis_cache', {}).get(cache_key)
            if cached_analysis:
                logger.info("ìºì‹œëœ AI ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")
                return cached_analysis

            # ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± - ì–¸ì–´ì™€ ë¶„ì„ ê¹Šì´ ë°˜ì˜
            prompt = self.generate_dynamic_prompt(llm_data, language, analysis_focus, analysis_depth)

            # ì–¸ì–´ì— ë”°ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
            if language == "ì˜ì–´":
                system_message = "You are a professional financial analyst providing investment insights. Please respond in English."
            else:
                system_message = "ë‹¹ì‹ ì€ íˆ¬ì ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."

            # API ìš”ì²­ ë°ì´í„° êµ¬ì„±
            api_url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.openai_api_key}"
            }

            # API ìš”ì²­ ë³´ë‚´ê¸°
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            # ë””ë²„ê¹…ì„ ìœ„í•œ ì–¸ì–´ ì„¤ì • ë¡œê¹…
            logger.info(f"AI ë¶„ì„ ìš”ì²­ - ì–¸ì–´: {language}, ë¶„ì„ ê¹Šì´: {analysis_depth}")

            response = requests.post(api_url, headers=headers, json=data)
            response_data = response.json()

            # ì‘ë‹µ ì²˜ë¦¬
            if "choices" in response_data and len(response_data["choices"]) > 0:
                analysis = response_data["choices"][0]["message"]["content"]

                # ê²°ê³¼ ìºì‹±
                if 'analysis_cache' not in st.session_state.comprehensive_data:
                    st.session_state.comprehensive_data['analysis_cache'] = {}
                st.session_state.comprehensive_data['analysis_cache'][cache_key] = analysis

                return analysis
            else:
                error_message = response_data.get("error", {}).get("message", "Unknown error")
                raise Exception(f"OpenAI API ì˜¤ë¥˜: {error_message}")

        except Exception as e:
            logger.error(f"AI ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
            raise

    def _display_unified_report(self, report_data, report_type, language, company_info, include_predictions=True):
        """í†µí•©ëœ ë¦¬í¬íŠ¸ ë‚´ìš© í‘œì‹œ (íƒ­ ëŒ€ì‹  ë‹¨ì¼ í™”ë©´)"""
        # íšŒì‚¬ ì •ë³´
        company_name = company_info["name"]
        company_symbol = company_info["symbol"]

        st.subheader(f"{company_name} ({company_symbol}) ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        st.caption(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d')}")

        # ì£¼ê°€ ì˜ˆì¸¡ ì„¹ì…˜ - ì„¤ì •ì— ë”°ë¼ ê°€ì¥ ë¨¼ì € í‘œì‹œ
        if include_predictions:
            # í˜„ì¬ í‘œì‹œí•  ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
            prediction_result = report_data.get('prediction_result')
            
            # 1. ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            if prediction_result is None:
                st.warning("ì£¼ê°€ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # 2. ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš°
            elif 'error' in prediction_result and prediction_result['error']:
                st.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤íŒ¨: {prediction_result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                
                # ë°ì´í„° ë¶€ì¡± ë¬¸ì œì¸ ê²½ìš° ìœ ìš©í•œ ì •ë³´ ì œê³µ
                if 'ë¶€ì¡±' in prediction_result.get('error_message', ''):
                    st.info("""
                    ### ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì£¼ê°€ ì˜ˆì¸¡ ë¶ˆê°€
                    
                    ìµœê·¼ ìƒì¥ëœ ê¸°ì—…ì´ë‚˜ ê±°ë˜ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ì´ ì–´ë µìŠµë‹ˆë‹¤.
                    ë‹¤ìŒê³¼ ê°™ì€ ëŒ€ì•ˆì„ ê³ ë ¤í•´ë³´ì„¸ìš”:
                    
                    1. **ê¸°ìˆ ì  ë¶„ì„** - ì œí•œëœ ë°ì´í„°ë¡œë„ ê¸°ë³¸ì ì¸ ê¸°ìˆ ì  ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    2. **ê¸°ë³¸ì  ë¶„ì„** - ì¬ë¬´ì œí‘œì™€ ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„ì„ í™œìš©í•˜ì„¸ìš”.
                    3. **ìœ ì‚¬ ê¸°ì—… ë¶„ì„** - ë™ì¢… ì—…ê³„ì˜ ìœ ì‚¬í•œ ê¸°ì—… ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
                    """)
            # 3. ì •ìƒì ì¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            else:
                # ì˜ˆì¸¡ íšŒì‚¬ì™€ í˜„ì¬ íšŒì‚¬ê°€ ë‹¤ë¥¸ ê²½ìš° ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                prediction_company = prediction_result.get('company_symbol', company_symbol)
                if prediction_company != company_symbol:
                    logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ì˜ íšŒì‚¬({prediction_company})ì™€ í˜„ì¬ íšŒì‚¬({company_symbol})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    st.warning("ì´ ê¸°ì—…ì— ëŒ€í•œ ì£¼ê°€ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    self._display_prediction_section(report_data, include_predictions, company_info)

        # AI ì¢…í•© ë¶„ì„
        st.markdown("### ğŸ§  ì¢…í•© AI ë¶„ì„")

        if "ai_analysis" in report_data and report_data["ai_analysis"]:
            st.markdown(report_data["ai_analysis"])
        else:
            st.warning("AI ë¶„ì„ ê²°ê³¼ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            
    def _display_prediction_section(self, report_data, include_predictions, company_info=None):
        """ì˜ˆì¸¡ ì„¹ì…˜ í‘œì‹œ - íšŒì‚¬ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸ ì¶”ê°€"""
        if not include_predictions:
            return

        st.write("## ğŸ“ˆ ì£¼ê°€ ì˜ˆì¸¡ ë¶„ì„")

        try:
            # ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            if 'prediction_result' not in report_data:
                st.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            prediction_result = report_data['prediction_result']
            
            # ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ í›„ ì¢…ë£Œ
            if 'error' in prediction_result and prediction_result['error']:
                st.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤íŒ¨: {prediction_result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                return
                
            # ì˜ˆì¸¡ íšŒì‚¬ì™€ í˜„ì¬ íšŒì‚¬ê°€ ë‹¤ë¥¸ ê²½ìš°
            current_symbol = company_info.get("symbol") if company_info else None
            prediction_company = prediction_result.get('company_symbol', current_symbol)
            
            if prediction_company != current_symbol:
                st.warning(f"ì´ ê¸°ì—…({current_symbol})ì— ëŒ€í•œ ì£¼ê°€ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ì˜ íšŒì‚¬({prediction_company})ì™€ í˜„ì¬ íšŒì‚¬({current_symbol})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

            # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            self._display_prediction_results(report_data, prediction_result)

            # ëª¨ë¸ í‰ê°€ ê²°ê³¼ í‘œì‹œ
            if 'model_evaluation' in report_data:
                with st.expander("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€", expanded=False):
                    symbol = company_info.get("symbol", "unknown") if company_info else "unknown"
                    self._display_model_evaluation(
                        report_data['model_evaluation'],
                        symbol
                    )

        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())

    def _display_prediction_results(self, stock_data, prediction_data):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” - ìƒˆë¡œìš´ ëª¨ë¸ ì§€ì› ì¶”ê°€"""
        # í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta

        try:
            if prediction_data is None:
                st.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            st.subheader("ì£¼ê°€ ì˜ˆì¸¡ ì°¨íŠ¸")

            # ëª¨ë¸ ìœ í˜• ê°€ì ¸ì˜¤ê¸° ë° í‘œì‹œ
            model_type = st.session_state.comprehensive_data.get('model_type', 'LSTM')
            st.write(f"#### ì‚¬ìš© ëª¨ë¸: {model_type}")

            # ëª¨ë¸ë³„ íŠ¹ì„± ì„¤ëª… ì¶”ê°€
            model_descriptions = {
                "LSTM": "ìˆœí™˜ ì‹ ê²½ë§ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°„ì  ì˜ì¡´ì„±ì„ ì˜ í¬ì°©í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.",
                "Transformer": "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ ì¸ì‹í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.",
                "ensemble": "LSTMê³¼ Transformer ëª¨ë¸ì„ ê²°í•©í•œ ì•™ìƒë¸” ëª¨ë¸ì…ë‹ˆë‹¤.",
                "TCN": "í™•ì¥ëœ ì»¨ë³¼ë£¨ì…˜ì„ í†µí•´ ë‹¤ì–‘í•œ ì‹œê°„ ìŠ¤ì¼€ì¼ì˜ íŒ¨í„´ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.",
                "TFT": "ì‹œê°„ íŠ¹ì„±ì„ ì—¬ëŸ¬ í•´ìƒë„ë¡œ ì²˜ë¦¬í•˜ê³  ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ìµœì‹  ëª¨ë¸ì…ë‹ˆë‹¤.",
                "N-BEATS": "ê³„ì¸µì  êµ¬ì¡°ì™€ ì—­íˆ¬ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë³µì¡í•œ ì‹œê³„ì—´ íŒ¨í„´ì„ í¬ì°©í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.",
                "hybrid": "ì—¬ëŸ¬ ì˜ˆì¸¡ ëª¨ë¸ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ëª¨ë¸ì…ë‹ˆë‹¤."
            }

            if model_type.lower() in model_descriptions:
                st.info(model_descriptions[model_type.lower()])

            # í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸”ì¸ ê²½ìš° ì‚¬ìš©ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ í‘œì‹œ
            if model_type.lower() == "hybrid" and 'model_weights' in prediction_data:
                st.write("##### ëª¨ë¸ ê°€ì¤‘ì¹˜")
                weights = prediction_data['model_weights']

                # ê°€ì¤‘ì¹˜ ì •ë³´ë¥¼ í‘œ í˜•íƒœë¡œ í‘œì‹œ
                weight_data = []
                for model, weight in weights.items():
                    if weight > 0:  # ê°€ì¤‘ì¹˜ê°€ 0ë³´ë‹¤ í° ëª¨ë¸ë§Œ í‘œì‹œ
                        weight_data.append({"ëª¨ë¸": model, "ê°€ì¤‘ì¹˜": f"{weight:.2f}"})

                if weight_data:
                    weight_df = pd.DataFrame(weight_data)
                    st.dataframe(weight_df, use_container_width=True)

            # stock_data íƒ€ì… í™•ì¸ ë° í•„ìš”ì‹œ ì¡°ì •
            history_df = None
            if stock_data is not None:
                if isinstance(stock_data, pd.DataFrame):
                    history_df = stock_data
                    logger.info("stock_dataë¥¼ DataFrameìœ¼ë¡œ ì‚¬ìš©")
                elif isinstance(stock_data, dict) and 'history_df' in stock_data:
                    # stock_dataê°€ dictì´ê³  history_df í‚¤ê°€ ìˆëŠ” ê²½ìš°
                    history_df = stock_data['history_df']
                    logger.info("stock_data['history_df']ë¥¼ DataFrameìœ¼ë¡œ ì‚¬ìš©")
                elif isinstance(stock_data, dict):
                    # prediction_dataì— history_dfê°€ ìˆëŠ”ì§€ í™•ì¸
                    if 'history_df' in prediction_data:
                        history_df = prediction_data['history_df']
                        logger.info("prediction_data['history_df']ë¥¼ DataFrameìœ¼ë¡œ ì‚¬ìš©")
                    else:
                        logger.warning("ìœ íš¨í•œ stock_data DataFrameì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # prediction_data êµ¬ì¡° í™•ì¸ ë° ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ
            prediction_result = None

            # case 1: prediction_dataê°€ ì´ë¯¸ ì˜ˆì¸¡ ê²°ê³¼ì¸ ê²½ìš°
            if 'predicted' in prediction_data or any(
                    k in prediction_data for k in ['predicted_prices', 'predictions', 'forecast']):
                prediction_result = prediction_data
                logger.info("ì§ì ‘ ì˜ˆì¸¡ ê²°ê³¼ ê°ì²´ ì‚¬ìš©")

            # case 2: 'prediction_result' í‚¤ê°€ ìˆëŠ” ì¤‘ì²© êµ¬ì¡°ì¸ ê²½ìš°
            elif 'prediction_result' in prediction_data and prediction_data['prediction_result'] is not None:
                prediction_result = prediction_data['prediction_result']
                logger.info("prediction_result í‚¤ì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ")

            # ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            if prediction_result is None:
                st.warning("ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.warning(f"prediction_data í‚¤: {list(prediction_data.keys())}")

                # prediction_dataê°€ dictì˜ dictì¸ ê²½ìš°, ëª¨ë“  ë‚´ë¶€ dictë¥¼ í™•ì¸
                for key, value in prediction_data.items():
                    if isinstance(value, dict) and (
                            'predicted' in value or 'predictions' in value or 'forecast' in value):
                        prediction_result = value
                        logger.info(f"'{key}' í‚¤ì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ")
                        break

            # ì—¬ì „íˆ ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            if prediction_result is None:
                st.error("ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.error(f"ì˜ˆì¸¡ ë°ì´í„° êµ¬ì¡°: {type(prediction_data)}")
                if isinstance(prediction_data, dict):
                    logger.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í‚¤: {list(prediction_data.keys())}")
                    # ë” ìì„¸í•œ êµ¬ì¡° í™•ì¸ì„ ìœ„í•œ ë¡œê¹…
                    for key, value in prediction_data.items():
                        logger.error(f"Key '{key}' type: {type(value)}")
                        if isinstance(value, dict):
                            logger.error(f"Key '{key}' sub-keys: {list(value.keys())}")
                return

            # ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
            # 'predicted' í‚¤ ë˜ëŠ” ëŒ€ì²´ í‚¤ í™•ì¸
            predicted_prices = None
            for key in ['predicted', 'predicted_prices', 'predictions', 'forecast', 'pred']:
                if key in prediction_result:
                    predicted_prices = prediction_result[key]
                    logger.info(f"ì˜ˆì¸¡ ê°€ê²©ì— '{key}' í‚¤ ì‚¬ìš©")
                    break

            if predicted_prices is None:
                st.error("ì˜ˆì¸¡ ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.error(f"prediction_result í‚¤: {list(prediction_result.keys())}")
                return

            # ì‹ ë¢° êµ¬ê°„ (ì—†ì„ ê²½ìš° None ì‚¬ìš©)
            confidence_high = prediction_result.get('confidence_high', None)
            confidence_low = prediction_result.get('confidence_low', None)

            # Prophet ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì—ì„œ)
            if model_type.lower() == "hybrid" and 'prophet_predictions' in prediction_result:
                prophet_data = prediction_result['prophet_predictions']

                # Prophet ì˜ˆì¸¡ ì¶”ê°€ í‘œì‹œ ì—¬ë¶€ í™•ì¸
                show_prophet = st.checkbox("Prophet ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ", value=True)

                if show_prophet and prophet_data is not None:
                    st.write("##### Prophet ì˜ˆì¸¡ ê²°ê³¼")
                    prophet_values = prophet_data.get('values', [])
                    prophet_lower = prophet_data.get('lower', [])
                    prophet_upper = prophet_data.get('upper', [])

                    if prophet_values and len(prophet_values) > 0:
                        # Prophet ì˜ˆì¸¡ ì‹œê°í™” (ê°„ë‹¨í•œ ì°¨íŠ¸)
                        try:
                            fig_prophet = go.Figure()
                            # ë‚ ì§œ ìƒì„±
                            dates = self.generate_trading_days(history_df.index[-1], len(prophet_values))

                            # Prophet ì˜ˆì¸¡ê°’
                            fig_prophet.add_trace(go.Scatter(
                                x=dates,
                                y=prophet_values,
                                mode='lines',
                                name='Prophet ì˜ˆì¸¡',
                                line=dict(color='orange', width=2)
                            ))

                            # ì‹ ë¢° êµ¬ê°„ (ìˆëŠ” ê²½ìš°)
                            if prophet_lower and prophet_upper and len(prophet_lower) == len(prophet_upper):
                                fig_prophet.add_trace(go.Scatter(
                                    x=dates + dates[::-1],
                                    y=prophet_upper + prophet_lower[::-1],
                                    fill='toself',
                                    fillcolor='rgba(255,165,0,0.2)',
                                    line=dict(color='rgba(255,255,255,0)'),
                                    name='Prophet ì‹ ë¢° êµ¬ê°„'
                                ))

                            fig_prophet.update_layout(
                                title="Prophet ì‹œê³„ì—´ ì˜ˆì¸¡",
                                xaxis_title="ë‚ ì§œ",
                                yaxis_title="ê°€ê²©",
                                height=300
                            )

                            st.plotly_chart(fig_prophet, use_container_width=True)
                        except Exception as e:
                            st.warning(f"Prophet ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

            # ì˜ˆì¸¡ ë‚ ì§œ (ì—†ì„ ê²½ìš° ìƒì„±)
            if 'dates' in prediction_result:
                prediction_dates = prediction_result['dates']
            else:
                # ë§ˆì§€ë§‰ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
                if history_df is not None and isinstance(history_df, pd.DataFrame) and not history_df.empty:
                    last_date = history_df.index[-1]
                    # ê±°ë˜ì¼(ì›”-ê¸ˆ) ê¸°ì¤€ ë‚ ì§œ ìƒì„±
                    prediction_dates = self.generate_trading_days(last_date, len(predicted_prices))
                else:
                    # ì˜¤ëŠ˜ë¶€í„° ê±°ë˜ì¼(ì›”-ê¸ˆ) ê¸°ì¤€ ë‚ ì§œ ìƒì„±
                    prediction_dates = self.generate_trading_days(datetime.now(), len(predicted_prices))

            # ë§ˆì§€ë§‰ ê°€ê²© (ì—†ì„ ê²½ìš° ê³„ì‚°)
            if 'last_price' in prediction_result:
                last_price = prediction_result['last_price']
            else:
                if history_df is not None and isinstance(history_df, pd.DataFrame) and not history_df.empty:
                    last_price = history_df['Close'].iloc[-1]
                else:
                    # ì˜ˆìƒ ë§ˆì§€ë§‰ ê°€ê²© (ì˜ˆì¸¡ ì‹œì‘ì )
                    last_price = predicted_prices[0] if len(predicted_prices) > 0 else 0
                    logger.warning("ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²© ì •ë³´ê°€ ì—†ì–´ ì˜ˆì¸¡ ì²« ê°€ê²©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

            # ê°€ê²© ë³€í™” ì¶”ì„¸ ê³„ì‚°
            price_change = predicted_prices[-1] - last_price
            price_change_percent = (price_change / last_price) * 100 if last_price > 0 else 0

            # ì˜ˆì¸¡ ë°©í–¥ í‘œì‹œ
            if price_change > 0:
                arrow = "â†—ï¸"
                color = "green"
                direction = "ìƒìŠ¹"
            else:
                arrow = "â†˜ï¸"
                color = "red"
                direction = "í•˜ë½"

            st.markdown(
                f"### ì˜ˆì¸¡ ë°©í–¥: <span style='color:{color};'>{arrow} {direction} ({price_change_percent:.2f}%)</span>",
                unsafe_allow_html=True)

            # ì§€í‘œ í‘œì‹œ
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    "í˜„ì¬ ê°€ê²©",
                    f"{last_price:,.0f}ì›"
                )

            with col2:
                st.metric(
                    f"{len(predicted_prices)}ì¼ í›„ ì˜ˆìƒ ê°€ê²©",
                    f"{predicted_prices[-1]:,.0f}ì›",
                    f"{price_change_percent:.2f}%"
                )

            with col3:
                if confidence_high is not None and confidence_low is not None:
                    uncertainty = ((confidence_high[-1] - confidence_low[-1]) / 2 / predicted_prices[-1] * 100)
                    st.metric(
                        "ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±",
                        f"Â±{uncertainty:.2f}%"
                    )

            # ìµœê·¼ ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²© ì°¨íŠ¸
            fig = go.Figure()

            # ë°ì´í„° ì¤€ë¹„
            recent_dates = []
            recent_prices = []

            # ìµœê·¼ ì‹¤ì œ ì£¼ê°€ ë°ì´í„° ì¤€ë¹„
            if history_df is not None and isinstance(history_df, pd.DataFrame) and not history_df.empty:
                historical_period = min(30, len(history_df))
                recent_dates = history_df.index[-historical_period:].tolist()
                recent_prices = history_df['Close'].values[-historical_period:].tolist()

            # ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„
            try:
                prediction_dates_list = list(prediction_dates) if not isinstance(prediction_dates,
                                                                                 list) else prediction_dates
                predicted_prices_list = list(predicted_prices) if not isinstance(predicted_prices,
                                                                                 list) else predicted_prices
            except Exception as e:
                logger.error(f"ì˜ˆì¸¡ ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
                # ë°±ì—… ë°©ë²•ìœ¼ë¡œ ìˆ˜ë™ ë³€í™˜ ì‹œë„
                try:
                    prediction_dates_list = []
                    for date in prediction_dates:
                        prediction_dates_list.append(date)

                    predicted_prices_list = []
                    for price in predicted_prices:
                        predicted_prices_list.append(float(price))
                except Exception as e2:
                    logger.error(f"ìˆ˜ë™ ë°ì´í„° ë³€í™˜ë„ ì‹¤íŒ¨: {str(e2)}")
                    st.error("ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    return

            # ì‹ ë¢° êµ¬ê°„ ë°ì´í„° ì¤€ë¹„
            confidence_high_list = []
            confidence_low_list = []

            if confidence_high is not None and confidence_low is not None:
                try:
                    confidence_high_list = list(confidence_high) if not isinstance(confidence_high,
                                                                                   list) else confidence_high
                    confidence_low_list = list(confidence_low) if not isinstance(confidence_low,
                                                                                 list) else confidence_low
                except Exception as e:
                    logger.error(f"ì‹ ë¢° êµ¬ê°„ ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
                    # ì‹ ë¢° êµ¬ê°„ì€ í•„ìˆ˜ê°€ ì•„ë‹ˆë¯€ë¡œ ë¬´ì‹œí•˜ê³  ì§„í–‰

            # ===== í•µì‹¬: Yì¶• ë²”ìœ„ ê³„ì‚°ì„ ìœ„í•œ ì½”ë“œ =====
            # 1. ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ê³  ì´ìƒì¹˜ ì œê±°
            def safe_float(x):
                try:
                    val = float(x)
                    if np.isnan(val) or np.isinf(val):
                        return None
                    return val
                except:
                    return None

            # ì£¼ìš” ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ Yì¶• ë²”ìœ„ ê³„ì‚° (ì‹ ë¢° êµ¬ê°„ ì œì™¸)
            core_prices = []

            # ì‹¤ì œ ê°€ê²© ì¶”ê°€
            core_prices.extend([safe_float(p) for p in recent_prices])

            # ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²© ì¶”ê°€
            if last_price is not None:
                core_prices.append(safe_float(last_price))

            # ì˜ˆì¸¡ ê°€ê²© ì¶”ê°€
            core_prices.extend([safe_float(p) for p in predicted_prices_list])

            # None ê°’ í•„í„°ë§
            core_prices = [p for p in core_prices if p is not None]

            # ê·¹ë‹¨ì  ì´ìƒì¹˜ ì œê±° (IQR ë°©ì‹)
            if len(core_prices) > 4:  # ì‚¬ë¶„ìœ„ìˆ˜ ê³„ì‚°ì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„° ê°œìˆ˜
                try:
                    # ì‚¬ë¶„ìœ„ìˆ˜ ê³„ì‚°
                    q1 = np.percentile(core_prices, 25)
                    q3 = np.percentile(core_prices, 75)
                    iqr = q3 - q1

                    # ì´ìƒì¹˜ ê²½ê³„ ê³„ì‚° (ì¼ë°˜ì ì¸ 1.5 ëŒ€ì‹  3ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ëœ ì—„ê²©í•˜ê²Œ)
                    lower_bound = q1 - 3 * iqr
                    upper_bound = q3 + 3 * iqr

                    # ì´ìƒì¹˜ ì œê±°ëœ ë°ì´í„°
                    filtered_prices = [p for p in core_prices if lower_bound <= p <= upper_bound]

                    # í•„í„°ë§ ê²°ê³¼ ë¡œê¹…
                    logger.info(f"ì›ë³¸ ë°ì´í„° ê°œìˆ˜: {len(core_prices)}, í•„í„°ë§ í›„: {len(filtered_prices)}")
                    logger.info(f"Q1: {q1}, Q3: {q3}, IQR: {iqr}")
                    logger.info(f"í•˜í•œ: {lower_bound}, ìƒí•œ: {upper_bound}")

                    # í•„í„°ë§ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
                    if len(filtered_prices) < len(core_prices) * 0.5:
                        logger.warning("í•„í„°ë§ìœ¼ë¡œ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì´ ì œê±°ë¨. í•„í„°ë§ ì™„í™”")
                        # ë” ê´€ëŒ€í•œ ê²½ê³„ë¡œ ë‹¤ì‹œ í•„í„°ë§
                        lower_bound = q1 - 5 * iqr
                        upper_bound = q3 + 5 * iqr
                        filtered_prices = [p for p in core_prices if lower_bound <= p <= upper_bound]

                    # ìµœì¢… ë°ì´í„° ì‚¬ìš©
                    if len(filtered_prices) > 0:
                        core_prices = filtered_prices
                except Exception as e:
                    logger.error(f"ì´ìƒì¹˜ ì œê±° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ìœ ì§€

            # 2. Yì¶• ë²”ìœ„ ì„¤ì •
            if core_prices:
                min_price = min(core_prices)
                max_price = max(core_prices)

                # ìµœì†Œ/ìµœëŒ€ ë™ì¼í•œ ê²½ìš° ì²˜ë¦¬
                if max_price == min_price:
                    padding = max(max_price * 0.05, 1)  # ìµœì†Œ 1 ë˜ëŠ” 5% ì¤‘ í° ê°’
                    min_price -= padding
                    max_price += padding
                else:
                    price_range = max_price - min_price

                    # ì—¬ë°± ì¶”ê°€ (ì¢€ë” ë„‰ë„‰í•˜ê²Œ)
                    padding = price_range * 0.12
                    min_price = min_price - padding
                    max_price = max_price + padding

                # ìŒìˆ˜ ë°©ì§€
                min_price = max(0, min_price) if min_price > -0.1 * max_price else min_price

                logger.info(f"ìµœì¢… Yì¶• ë²”ìœ„: {min_price:.2f} ~ {max_price:.2f}")
            else:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ìë™ ë²”ìœ„ ì‚¬ìš©
                logger.warning("ìœ íš¨í•œ ê°€ê²© ë°ì´í„°ê°€ ì—†ì–´ ìë™ ë²”ìœ„ ì‚¬ìš©")
                min_price = None
                max_price = None

            # ê·¸ë˜í”„ ë°ì´í„° ì¶”ê°€
            # ì‹¤ì œ ê°€ê²© ì¶”ê°€
            if recent_dates and recent_prices:
                fig.add_trace(
                    go.Scatter(
                        x=recent_dates,
                        y=recent_prices,
                        name="ì‹¤ì œ ê°€ê²©",
                        line=dict(color='royalblue', width=3)
                    )
                )

            # ì˜ˆì¸¡ ê°€ê²© ì¶”ê°€
            if prediction_dates_list and predicted_prices_list:
                fig.add_trace(
                    go.Scatter(
                        x=prediction_dates_list,
                        y=predicted_prices_list,
                        mode='lines+markers',
                        name='ì˜ˆì¸¡ ê°€ê²©',
                        line=dict(color='red', width=2),
                        marker=dict(size=6)
                    )
                )

            # ì‹ ë¢° êµ¬ê°„ ì¶”ê°€ (ì˜µì…˜)
            if prediction_dates_list and confidence_high_list and confidence_low_list:
                try:
                    dates_x = prediction_dates_list
                    dates_x_rev = dates_x[::-1]

                    fig.add_trace(
                        go.Scatter(
                            x=dates_x + dates_x_rev,
                            y=confidence_high_list + confidence_low_list[::-1],
                            fill='toself',
                            fillcolor='rgba(0,100,80,0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name='90% ì‹ ë¢° êµ¬ê°„',
                            showlegend=True
                        )
                    )
                except Exception as e:
                    logger.warning(f"ì‹ ë¢° êµ¬ê°„ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")

            # ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²© í‘œì‹œ
            if history_df is not None and isinstance(history_df, pd.DataFrame) and not history_df.empty:
                last_actual_date = history_df.index[-1]
                fig.add_trace(
                    go.Scatter(
                        x=[last_actual_date],
                        y=[last_price],
                        mode='markers',
                        name='ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²©',
                        marker=dict(color='blue', size=8, symbol='star')
                    )
                )

            # ê²½ê³„ í‘œì‹œë¥¼ ìœ„í•œ ì£¼ì„ ì¶”ê°€
            if history_df is not None and isinstance(history_df, pd.DataFrame) and not history_df.empty:
                current_date = history_df.index[-1]

                fig.add_annotation(
                    x=current_date,
                    y=1.05,
                    yref="paper",
                    text="í˜„ì¬",
                    showarrow=True,
                    arrowhead=2,
                    arrowcolor="gray",
                    arrowwidth=1.5,
                    arrowsize=1,
                    ax=0,
                    ay=-30
                )

                # ìˆ˜ì§ì„  ëŒ€ì‹  ì‹œê°ì ìœ¼ë¡œ ì˜ì—­ êµ¬ë¶„
                if len(prediction_dates) > 0:
                    fig.add_vrect(
                        x0=current_date,
                        x1=prediction_dates[0],
                        fillcolor="gray",
                        opacity=0.1,
                        layer="below",
                        line_width=0
                    )

            # Yì¶• ë²”ìœ„ ì ìš© ë° ê·¸ë¦¬ë“œ ì„¤ì • (í•œ ë²ˆë§Œ ì„¤ì •)
            if min_price is not None and max_price is not None:
                fig.update_yaxes(
                    range=[min_price, max_price],
                    autorange=False,  # ìë™ ë²”ìœ„ ë¹„í™œì„±í™”
                    showgrid=True,  # ê·¸ë¦¬ë“œ í‘œì‹œ
                    gridwidth=1,  # ê·¸ë¦¬ë“œ ë‘ê»˜
                    gridcolor='rgba(0,0,0,0.1)',  # ê·¸ë¦¬ë“œ ìƒ‰ìƒ
                    zeroline=True,  # 0 ê¸°ì¤€ì„  í‘œì‹œ
                    zerolinewidth=1.5,  # 0 ê¸°ì¤€ì„  ë‘ê»˜
                    zerolinecolor='rgba(0,0,0,0.2)'  # 0 ê¸°ì¤€ì„  ìƒ‰ìƒ
                )
            else:
                # ìë™ ë²”ìœ„ì—ë„ ê·¸ë¦¬ë“œëŠ” ì ìš©
                fig.update_yaxes(
                    autorange=True,
                    showgrid=True,
                    gridwidth=1,
                    gridcolor='rgba(0,0,0,0.1)'
                )

            # ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title='ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²© ë¹„êµ',
                xaxis_title='ë‚ ì§œ',
                yaxis_title='ì£¼ê°€',
                hovermode='x unified',
                showlegend=True,
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                )
            )

            # Xì¶• ë‚ ì§œ í¬ë§· ì„¤ì •
            fig.update_xaxes(
                tickformat="%mì›” %dì¼ (%a)",  # ìš”ì¼ í‘œì‹œ
                tickformatstops=[
                    dict(dtickrange=[None, 86400000], value="%mì›” %dì¼ (%a)"),
                    dict(dtickrange=[86400000, 604800000], value="%mì›” %dì¼ (%a)"),
                    dict(dtickrange=[604800000, "M1"], value="%mì›” %dì¼"),
                    dict(dtickrange=["M1", "M12"], value="%mì›”"),
                    dict(dtickrange=["M12", None], value="%Yë…„")
                ]
            )

            # ê·¸ë˜í”„ í‘œì‹œ
            st.plotly_chart(fig, use_container_width=True)

            # ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”
            with st.expander("ìƒì„¸ ì˜ˆì¸¡ ê°€ê²©", expanded=False):
                try:
                    # ë‚ ì§œ í¬ë§· ë³€í™˜
                    formatted_dates = []
                    formatted_weekdays = []

                    for date in prediction_dates:
                        try:
                            # datetime ê°ì²´ ë³€í™˜ ë° í¬ë§·íŒ…
                            if hasattr(date, 'strftime'):
                                formatted_dates.append(date.strftime('%Y-%m-%d (%a)'))
                                formatted_weekdays.append(date.strftime('%A'))
                            else:
                                # datetimeì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜ ì‹œë„
                                d = pd.Timestamp(date)
                                formatted_dates.append(d.strftime('%Y-%m-%d (%a)'))
                                formatted_weekdays.append(d.strftime('%A'))
                        except Exception as e:
                            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê°’ ì‚¬ìš©
                            logger.warning(f"ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
                            formatted_dates.append(str(date))
                            formatted_weekdays.append("Unknown")

                    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    pred_df = pd.DataFrame({
                        'ë‚ ì§œ': formatted_dates,
                        'ìš”ì¼': formatted_weekdays,
                        'ì˜ˆì¸¡ ê°€ê²©': [f"{price:,.0f}ì›" for price in predicted_prices],
                        'ë³€í™”ìœ¨(%)': [(p - last_price) / last_price * 100 for p in predicted_prices]
                    })

                    if confidence_high is not None and confidence_low is not None:
                        pred_df['ìƒí•œ ì‹ ë¢°êµ¬ê°„'] = [f"{price:,.0f}ì›" for price in confidence_high]
                        pred_df['í•˜í•œ ì‹ ë¢°êµ¬ê°„'] = [f"{price:,.0f}ì›" for price in confidence_low]
                        pred_df['ë¶ˆí™•ì‹¤ì„±(Â±%)'] = [((high - low) / 2 / pred) * 100 for high, low, pred in
                                               zip(confidence_high, confidence_low, predicted_prices)]

                    # ìš”ì¼ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ì„œì‹ ì„¤ì •
                    def highlight_weekday(s):
                        return [
                            'background-color: #f2f2f2' if '(Mon)' in val or '(ì›”)' in val else ''
                            for val in s
                        ]

                    # ì ìš©í•˜ê¸° ì „ì— í•œê¸€ ìš”ì¼ë¡œ ë³€í™˜
                    weekday_map = {
                        'Monday': 'ì›”ìš”ì¼',
                        'Tuesday': 'í™”ìš”ì¼',
                        'Wednesday': 'ìˆ˜ìš”ì¼',
                        'Thursday': 'ëª©ìš”ì¼',
                        'Friday': 'ê¸ˆìš”ì¼'
                    }
                    pred_df['ìš”ì¼'] = pred_df['ìš”ì¼'].map(lambda x: weekday_map.get(x, x))

                    # ìŠ¤íƒ€ì¼ì„ ì ìš©í•œ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                    st.dataframe(pred_df.style.apply(highlight_weekday, subset=['ë‚ ì§œ']), use_container_width=True)

                except Exception as e:
                    logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    # ê°„ë‹¨í•œ í…Œì´ë¸”ë¡œ ëŒ€ì²´
                    simple_df = pd.DataFrame({
                        'ë‚ ì§œ ì¸ë±ìŠ¤': range(len(predicted_prices)),
                        'ì˜ˆì¸¡ ê°€ê²©': [f"{price:,.0f}ì›" for price in predicted_prices],
                        'ë³€í™”ìœ¨(%)': [f"{((p - last_price) / last_price * 100):.2f}%" for p in predicted_prices]
                    })
                    st.dataframe(simple_df, use_container_width=True)

            # ì˜ˆì¸¡ í•´ì„ ì¶”ê°€
            st.subheader("ì˜ˆì¸¡ ê²°ê³¼ í•´ì„")

            # ì˜ˆì¸¡ ê¸°ê°„ì— ë”°ë¥¸ ë¶„ì„
            short_term = predicted_prices[0:7]  # 1ì£¼
            mid_term = predicted_prices[7:21]  # 2-3ì£¼
            long_term = predicted_prices[21:]  # 3ì£¼ ì´ìƒ

            # ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ì¶”ì„¸ ê³„ì‚°
            short_term_trend = "ìƒìŠ¹" if short_term[-1] > short_term[0] else "í•˜ë½"
            mid_term_trend = "ìƒìŠ¹" if len(mid_term) > 0 and mid_term[-1] > mid_term[0] else "í•˜ë½" if len(
                mid_term) > 0 else "ë°ì´í„° ì—†ìŒ"
            long_term_trend = "ìƒìŠ¹" if len(long_term) > 0 and long_term[-1] > long_term[0] else "í•˜ë½" if len(
                long_term) > 0 else "ë°ì´í„° ì—†ìŒ"

            col1, col2, col3 = st.columns(3)

            with col1:
                st.write("#### ë‹¨ê¸° ì „ë§ (7ì¼)")
                short_change = (short_term[-1] - last_price) / last_price * 100
                short_color = "green" if short_change > 0 else "red"
                st.markdown(f"**ì˜ˆìƒ ë³€ë™ë¥ :** <span style='color:{short_color};'>{short_change:+.2f}%</span>",
                            unsafe_allow_html=True)
                st.write(f"**ì¶”ì„¸:** {short_term_trend}")

                # í•´ì„
                if short_change > 3:
                    st.success("ë‹¨ê¸°ì ìœ¼ë¡œ ê°•í•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                elif short_change > 0:
                    st.info("ë‹¨ê¸°ì ìœ¼ë¡œ ì™„ë§Œí•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                elif short_change > -3:
                    st.warning("ë‹¨ê¸°ì ìœ¼ë¡œ ì†Œí­ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                else:
                    st.error("ë‹¨ê¸°ì ìœ¼ë¡œ í° í­ì˜ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")

            with col2:
                st.write("#### ì¤‘ê¸° ì „ë§ (7-21ì¼)")
                if len(mid_term) > 0:
                    mid_change = (mid_term[-1] - last_price) / last_price * 100
                    mid_color = "green" if mid_change > 0 else "red"
                    st.markdown(f"**ì˜ˆìƒ ë³€ë™ë¥ :** <span style='color:{mid_color};'>{mid_change:+.2f}%</span>",
                                unsafe_allow_html=True)
                    st.write(f"**ì¶”ì„¸:** {mid_term_trend}")

                    # í•´ì„
                    if mid_change > 5:
                        st.success("ì¤‘ê¸°ì ìœ¼ë¡œ ê°•í•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    elif mid_change > 0:
                        st.info("ì¤‘ê¸°ì ìœ¼ë¡œ ì™„ë§Œí•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    elif mid_change > -5:
                        st.warning("ì¤‘ê¸°ì ìœ¼ë¡œ ì†Œí­ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    else:
                        st.error("ì¤‘ê¸°ì ìœ¼ë¡œ í° í­ì˜ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                else:
                    st.info("ì¤‘ê¸° ì˜ˆì¸¡ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            with col3:
                st.write("#### ì¥ê¸° ì „ë§ (21ì¼ ì´ìƒ)")
                if len(long_term) > 0:
                    long_change = (long_term[-1] - last_price) / last_price * 100
                    long_color = "green" if long_change > 0 else "red"
                    st.markdown(f"**ì˜ˆìƒ ë³€ë™ë¥ :** <span style='color:{long_color};'>{long_change:+.2f}%</span>",
                                unsafe_allow_html=True)
                    st.write(f"**ì¶”ì„¸:** {long_term_trend}")

                    # í•´ì„
                    if long_change > 10:
                        st.success("ì¥ê¸°ì ìœ¼ë¡œ ê°•í•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    elif long_change > 0:
                        st.info("ì¥ê¸°ì ìœ¼ë¡œ ì™„ë§Œí•œ ìƒìŠ¹ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    elif long_change > -10:
                        st.warning("ì¥ê¸°ì ìœ¼ë¡œ ì†Œí­ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                    else:
                        st.error("ì¥ê¸°ì ìœ¼ë¡œ í° í­ì˜ í•˜ë½ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
                else:
                    st.info("ì¥ê¸° ì˜ˆì¸¡ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # ì¢…í•© ë¶„ì„
            st.write("#### ì¢…í•© ë¶„ì„")

            # ì¶”ì„¸ ë³€í™” ê°ì§€
            trend_changes = []
            if short_term_trend != mid_term_trend and mid_term_trend != "ë°ì´í„° ì—†ìŒ":
                trend_changes.append(f"ë‹¨ê¸°({short_term_trend})ì—ì„œ ì¤‘ê¸°({mid_term_trend})ë¡œ ì¶”ì„¸ ë³€í™”")

            if mid_term_trend != long_term_trend and mid_term_trend != "ë°ì´í„° ì—†ìŒ" and long_term_trend != "ë°ì´í„° ì—†ìŒ":
                trend_changes.append(f"ì¤‘ê¸°({mid_term_trend})ì—ì„œ ì¥ê¸°({long_term_trend})ë¡œ ì¶”ì„¸ ë³€í™”")

            # ë³€ë™ì„± ë¶„ì„
            volatility = np.std(predicted_prices) / np.mean(predicted_prices) * 100

            # ì¢…í•© í•´ì„
            analysis_points = []

            # ì¶”ì„¸ ê¸°ë°˜ ë¶„ì„
            if price_change_percent > 0:
                if volatility > 5:
                    analysis_points.append("ì „ì²´ì ìœ¼ë¡œ ìƒìŠ¹ ì¶”ì„¸ì´ë‚˜ ë³€ë™ì„±ì´ ë†’ì•„ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    analysis_points.append("ì „ì²´ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒìŠ¹ ì¶”ì„¸ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.")
            else:
                if volatility > 5:
                    analysis_points.append("ì „ì²´ì ìœ¼ë¡œ í•˜ë½ ì¶”ì„¸ì´ë©° ë³€ë™ì„±ì´ ë†’ìŠµë‹ˆë‹¤. íˆ¬ìì— ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    analysis_points.append("ì „ì²´ì ìœ¼ë¡œ ì™„ë§Œí•œ í•˜ë½ ì¶”ì„¸ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.")

            # ì¶”ì„¸ ë³€í™” ê°ì§€ ì‹œ ë¶„ì„
            if trend_changes:
                analysis_points.append("ì˜ˆì¸¡ ê¸°ê°„ ë‚´ ì¶”ì„¸ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤: " + ", ".join(trend_changes))

            # ë³€ë™ì„± ë¶„ì„
            if volatility < 2:
                analysis_points.append("ì˜ˆì¸¡ëœ ì£¼ê°€ ë³€ë™ì„±ì´ ë‚®ì•„ ë¹„êµì  ì•ˆì •ì ì¸ ì›€ì§ì„ì´ ì˜ˆìƒë©ë‹ˆë‹¤.")
            elif volatility < 5:
                analysis_points.append("ì˜ˆì¸¡ëœ ì£¼ê°€ ë³€ë™ì„±ì´ ì¤‘ê°„ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            else:
                analysis_points.append(f"ì˜ˆì¸¡ëœ ì£¼ê°€ ë³€ë™ì„±ì´ ë†’ìŠµë‹ˆë‹¤({volatility:.2f}%). ë‹¨ê¸° ë§¤ë§¤ ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

            # ì‚¬ìš©ëœ íŠ¹ì„± ì •ë³´ í‘œì‹œ
            if 'selected_features' in prediction_data:
                features = prediction_data['selected_features']
                if features:
                    if features == ['Auto'] or 'Auto' in features:
                        analysis_points.append("ìë™ íŠ¹ì„± ì„ íƒ ì•Œê³ ë¦¬ì¦˜ì´ ìµœì ì˜ íŠ¹ì„±ì„ ì„ íƒí•˜ì—¬ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        analysis_points.append(f"ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì£¼ìš” íŠ¹ì„±: {', '.join(features)}")

            # ëª¨ë¸ ìœ í˜•ë³„ ì¶”ê°€ ë¶„ì„
            if model_type and model_type.lower() in model_descriptions:
                if model_type.lower() == "hybrid":
                    analysis_points.append("í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì¥ì ì„ ê²°í•©í•œ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.")
                    if 'model_weights' in prediction_data:
                        weights = prediction_data['model_weights']
                        top_model = max(weights.items(), key=lambda x: x[1])[0]
                        analysis_points.append(f"ì•™ìƒë¸”ì—ì„œ ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ëª¨ë¸ì€ '{top_model}'ì…ë‹ˆë‹¤.")
                elif model_type.upper() == "TFT":
                    analysis_points.append("TFT ëª¨ë¸ì€ ì‹œê°„ì  íŠ¹ì„±ê³¼ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ ì˜ í¬ì°©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
                elif model_type.upper() == "TCN":
                    analysis_points.append("TCN ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì‹œê°„ ìŠ¤ì¼€ì¼ì˜ íŒ¨í„´ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.")
                elif model_type.upper() == "N-BEATS":
                    analysis_points.append("N-BEATS ëª¨ë¸ì€ ì¶”ì„¸ì™€ ê³„ì ˆì„±ì„ ë¶„ë¦¬í•˜ì—¬ ë¶„ì„í•˜ë¯€ë¡œ ë³µì¡í•œ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤.")

            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            for point in analysis_points:
                st.write(f"- {point}")

        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())

            # ì˜¤ë¥˜ ì‹œ ì˜ˆì¸¡ ê²°ê³¼ êµ¬ì¡° ë¡œê¹…
            if prediction_data is not None:
                logger.error(f"ì˜ˆì¸¡ ë°ì´í„° í‚¤: {list(prediction_data.keys() if isinstance(prediction_data, dict) else [])}")
                logger.error(f"ì˜ˆì¸¡ ë°ì´í„° êµ¬ì¡°: {type(prediction_data)}")

            st.info("ì˜ˆì¸¡ ê²°ê³¼ì— ì ‘ê·¼í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê°œë°œìì—ê²Œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ë„ë¡ ìš”ì²­í•˜ì„¸ìš”.")














    def generate_trading_days(self, start_date, num_days):
        """
        ì£¼ì–´ì§„ ì‹œì‘ì¼ë¡œë¶€í„° ì§€ì •ëœ ìˆ˜ì˜ ê±°ë˜ì¼(ì›”-ê¸ˆ)ì„ ìƒì„±í•©ë‹ˆë‹¤.
        ê³µíœ´ì¼ì€ ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        Args:
            start_date (datetime.date): ì‹œì‘ ë‚ ì§œ
            num_days (int): ìƒì„±í•  ê±°ë˜ì¼ ìˆ˜

        Returns:
            list: ê±°ë˜ì¼ ëª©ë¡ (datetime.date ê°ì²´)
        """
        import pandas as pd
        from datetime import datetime, timedelta

        # ì‹œì‘ì¼ì´ datetime ê°ì²´ê°€ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(start_date, datetime) and not isinstance(start_date, pd.Timestamp):
            try:
                start_date = pd.Timestamp(start_date)
            except:
                start_date = datetime.now()

        # ì‹œì‘ì¼ ë‹¤ìŒ ë‚ ë¶€í„° ì‹œì‘ (ì˜¤ëŠ˜ì€ ì´ë¯¸ ì§€ë‚œ ê±°ë˜ì¼)
        start_date += timedelta(days=1)

        # ì‹œì‘ì¼ì´ ì£¼ë§ì´ë©´ ë‹¤ìŒ ì›”ìš”ì¼ë¡œ ì¡°ì •
        while start_date.weekday() > 4:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
            start_date += timedelta(days=1)  # ë‹¤ìŒ ë‚ ë¡œ ì´ë™

        # ê±°ë˜ì¼ ìƒì„±
        trading_days = []
        current_date = start_date

        while len(trading_days) < num_days:
            if current_date.weekday() < 5:  # ì›”ìš”ì¼(0)ë¶€í„° ê¸ˆìš”ì¼(4)ê¹Œì§€ë§Œ
                trading_days.append(current_date)
            current_date += timedelta(days=1)

        return trading_days

    def _display_model_evaluation(self, evaluation_results, company_code=None):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ í‘œì‹œ - yì¶• ë²”ìœ„ ê°œì„ """
        try:
            # ê³ ìœ í•œ key ìƒì„±ì„ ìœ„í•œ ì ‘ë‘ì‚¬ ì„¤ì •
            timestamp = int(time.time() * 1000)
            random_suffix = np.random.randint(1000, 9999)
            prefix = f"{company_code}_{timestamp}_{random_suffix}_" if company_code else f"eval_{timestamp}_{random_suffix}_"

            st.write("### ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")

            # ì§€í‘œ í‘œì‹œ
            st.write("**ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ**")

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("MSE (í‰ê·  ì œê³± ì˜¤ì°¨)", f"{evaluation_results.get('mse', 0):.2f}")

            with col2:
                st.metric("RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)", f"{evaluation_results.get('rmse', 0):.2f}")
                if 'relative_rmse' in evaluation_results:
                    st.metric("ìƒëŒ€ RMSE (%)", f"{evaluation_results['relative_rmse']:.2f}%")

            with col3:
                st.metric("MAPE (í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨)", f"{evaluation_results.get('mape', 0):.2f}%")

            # í•´ì„ ê°€ì´ë“œ
            if 'relative_rmse' in evaluation_results:
                if evaluation_results['relative_rmse'] < 3:
                    st.success("ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ê°€ í˜„ì¬ ì£¼ê°€ì˜ 3% ë¯¸ë§Œìœ¼ë¡œ ë¹„êµì  ì •í™•í•©ë‹ˆë‹¤.")
                elif evaluation_results['relative_rmse'] < 5:
                    st.info("ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ê°€ í˜„ì¬ ì£¼ê°€ì˜ 3~5% ìˆ˜ì¤€ìœ¼ë¡œ ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
                else:
                    st.warning("ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ê°€ í˜„ì¬ ì£¼ê°€ì˜ 5% ì´ìƒìœ¼ë¡œ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ê·¸ë˜í”„ ê°œì„ 
            if 'y_test' in evaluation_results and 'y_pred' in evaluation_results:
                # ë°ì´í„° ì¤€ë¹„ ë° ìœ íš¨ì„± ê²€ì‚¬
                y_test_orig = evaluation_results['y_test']
                y_pred_orig = evaluation_results['y_pred']

                # ë°ì´í„° í˜•íƒœ ê²€ì‚¬ ë° ë³€í™˜
                if isinstance(y_test_orig, list) or isinstance(y_test_orig, np.ndarray):
                    # 2ì°¨ì› ë°°ì—´ì¸ ê²½ìš° 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
                    if hasattr(y_test_orig, 'shape') and len(y_test_orig.shape) > 1:
                        y_test_data = y_test_orig.flatten()
                    else:
                        y_test_data = np.array(y_test_orig)

                    # 2ì°¨ì› ë°°ì—´ì¸ ê²½ìš° 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
                    if hasattr(y_pred_orig, 'shape') and len(y_pred_orig.shape) > 1:
                        y_pred_data = y_pred_orig.flatten()
                    else:
                        y_pred_data = np.array(y_pred_orig)

                    # ë°ì´í„° ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ë§ì€ í¬ì¸íŠ¸ëŠ” ê·¸ë˜í”„ë¥¼ ëŠë¦¬ê²Œ ë§Œë“¦)
                    max_points = 100
                    if len(y_test_data) > max_points:
                        # ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
                        step = len(y_test_data) // max_points
                        y_test_data = y_test_data[::step]
                        y_pred_data = y_pred_data[::step]

                    # ì‹¤ì œë¡œ ë°ì´í„° ë³€í™”ê°€ ìˆëŠ”ì§€ í™•ì¸
                    y_test_range = np.max(y_test_data) - np.min(y_test_data)
                    y_pred_range = np.max(y_pred_data) - np.min(y_pred_data)

                    if y_test_range > 0.001 and y_pred_range > 0.001:  # ì˜ë¯¸ ìˆëŠ” ë³€í™”ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê·¸ë˜í”„ ìƒì„±
                        fig = go.Figure()

                        # Xì¶• ì¸ë±ìŠ¤ ìƒì„±
                        x_indices = np.arange(len(y_test_data))

                        # ì ˆëŒ€ ì˜¤ì°¨ ê³„ì‚°
                        error_data = np.abs(y_test_data - y_pred_data)

                        # ===== Yì¶• ë²”ìœ„ ê°œì„ ì„ ìœ„í•œ ì½”ë“œ =====
                        # ëª¨ë“  ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²©)
                        all_prices = np.concatenate([y_test_data, y_pred_data])

                        # ìµœì†Œ/ìµœëŒ€ê°’ ë° ë²”ìœ„ ê³„ì‚°
                        min_price = np.min(all_prices)
                        max_price = np.max(all_prices)
                        price_range = max_price - min_price

                        # ì—¬ë°± ì¶”ê°€ (ë²”ìœ„ì˜ 10%)
                        padding = price_range * 0.1
                        y_min = min_price - padding
                        y_max = max_price + padding

                        # ì‹¤ì œ ê°€ê²©
                        fig.add_trace(
                            go.Scatter(
                                x=x_indices,
                                y=y_test_data,
                                mode='lines',
                                name='ì‹¤ì œ ê°€ê²©',
                                line=dict(color='royalblue', width=3)
                            )
                        )

                        # ì˜ˆì¸¡ ê°€ê²©
                        fig.add_trace(
                            go.Scatter(
                                x=x_indices,
                                y=y_pred_data,
                                mode='lines',
                                name='ì˜ˆì¸¡ ê°€ê²©',
                                line=dict(color='firebrick', width=3, dash='dash')
                            )
                        )

                        # Yì¶• ë²”ìœ„ ì„¤ì • (ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²©ë§Œ í¬í•¨)
                        fig.update_layout(
                            yaxis=dict(
                                range=[y_min, y_max],
                                title=dict(text="ì£¼ê°€", font=dict(color="black")), 
                                side="left"
                            )
                        )
                        # fig.update_layout(
                        #     yaxis=dict(
                        #         range=[y_min, y_max],
                        #         title="ì£¼ê°€",
                        #         titlefont=dict(color="black"),
                        #         side="left"
                        #     )
                        # )

                        # ë³„ë„ì˜ Yì¶•ì— ì˜¤ì°¨ í‘œì‹œ (ë‘ ë²ˆì§¸ Yì¶•)
                        fig.add_trace(
                            go.Scatter(
                                x=x_indices,
                                y=error_data,
                                mode='lines',
                                name='ì ˆëŒ€ ì˜¤ì°¨',
                                line=dict(color='green', width=2, dash='dot'),
                                yaxis="y2"  # ë‘ ë²ˆì§¸ Yì¶•ì— í‘œì‹œ
                            )
                        )

                        # ë‘ ë²ˆì§¸ Yì¶• ì„¤ì • (ì˜¤ì°¨ìš©)
                        error_max = np.max(error_data)
                        fig.update_layout(
                            yaxis2=dict(
                                title=dict(text="ì ˆëŒ€ ì˜¤ì°¨", font=dict(color="green")),  
                                tickfont=dict(color="green"),
                                anchor="x",
                                overlaying="y",
                                side="right",
                                range=[0, error_max * 1.1]  # ì˜¤ì°¨ì˜ ìµœëŒ€ê°’ì— ë§ì¶° ì„¤ì •
                            )
                        )
                        # fig.update_layout(
                        #     yaxis2=dict(
                        #         title="ì ˆëŒ€ ì˜¤ì°¨",
                        #         titlefont=dict(color="green"),
                        #         tickfont=dict(color="green"),
                        #         anchor="x",
                        #         overlaying="y",
                        #         side="right",
                        #         range=[0, error_max * 1.1]  # ì˜¤ì°¨ì˜ ìµœëŒ€ê°’ì— ë§ì¶° ì„¤ì •
                        #     )
                        # )

                        # ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •
                        fig.update_layout(
                            title='í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥',
                            xaxis_title='ìƒ˜í”Œ ì¸ë±ìŠ¤',
                            height=400,
                            hovermode='x unified',
                            # ì—¬ë°± ìµœì†Œí™”
                            margin=dict(l=40, r=40, t=40, b=40),
                            legend=dict(
                                orientation="h",  # ìˆ˜í‰ ë ˆì´ì•„ì›ƒ
                                yanchor="bottom",
                                y=1.02,
                                xanchor="right",
                                x=1
                            )
                        )

                        # Xì¶• ìˆ«ì í…Œì´ë¸” í˜•ì‹ ì¡°ì •
                        fig.update_xaxes(
                            showticklabels=True,  # ëˆˆê¸ˆ ë ˆì´ë¸” í‘œì‹œ
                            tickvals=x_indices[::max(1, len(x_indices) // 10)],  # 10ê°œ ì •ë„ì˜ ëˆˆê¸ˆë§Œ í‘œì‹œ
                            ticktext=[f"{i + 1}" for i in range(0, len(x_indices), max(1, len(x_indices) // 10))]
                            # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆ«ìë¡œ í‘œì‹œ
                        )

                        st.plotly_chart(fig, use_container_width=True, key=f"{prefix}test_vs_pred_chart")
                    else:
                        st.warning("ë°ì´í„° ë³€í™”ê°€ ë„ˆë¬´ ì‘ì•„ ì˜ë¯¸ ìˆëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("í…ŒìŠ¤íŠ¸ ë° ì˜ˆì¸¡ ë°ì´í„° í˜•ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                # ì˜¤ì°¨ ë¶„ì„
                st.write("**ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„**")

                # ì˜¤ì°¨ íˆìŠ¤í† ê·¸ë¨
                if 'errors' in evaluation_results and len(evaluation_results['errors']) > 0:
                    fig_hist = go.Figure()
                    fig_hist.add_trace(
                        go.Histogram(
                            x=evaluation_results['errors'],
                            nbinsx=30,
                            name='ì˜¤ì°¨ ë¶„í¬',
                            marker_color='royalblue'
                        )
                    )

                    fig_hist.update_layout(
                        title='ì˜ˆì¸¡ ì˜¤ì°¨ íˆìŠ¤í† ê·¸ë¨',
                        xaxis_title='ì˜¤ì°¨',
                        yaxis_title='ë¹ˆë„',
                        height=300,
                        margin=dict(l=40, r=40, t=40, b=40)  # ì—¬ë°± ìµœì†Œí™”
                    )

                    st.plotly_chart(fig_hist, use_container_width=True, key=f"{prefix}error_distribution_chart")

                # ì˜¤ì°¨ í†µê³„
                mean_error = evaluation_results.get('mean_error', np.mean(evaluation_results.get('errors', [0])))
                std_error = evaluation_results.get('std_error', np.std(evaluation_results.get('errors', [0])))

                st.write(f"**ì˜¤ì°¨ í‰ê· **: {mean_error:.2f}")
                st.write(f"**ì˜¤ì°¨ í‘œì¤€í¸ì°¨**: {std_error:.2f}")

                # í¸í–¥ì„± ë¶„ì„
                bias = evaluation_results.get('bias', 'unknown')
                if bias == 'unbiased' or np.abs(mean_error) < std_error * 0.5:
                    st.success("ì˜ˆì¸¡ ì˜¤ì°¨ê°€ ì •ê·œë¶„í¬ì— ê°€ê¹Œìš°ë©°, í‰ê· ì´ 0ì— ê°€ê¹Œì›Œ ëª¨ë¸ì´ í¸í–¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ì˜ˆì¸¡ ì˜¤ì°¨ì˜ í‰ê· ì´ 0ì—ì„œ ë²—ì–´ë‚˜ ìˆì–´ ëª¨ë¸ì— í¸í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # ì‹ ë¢°ë„ í‰ê°€
            if 'relative_rmse' in evaluation_results:
                st.write("**ì˜ˆì¸¡ ì‹ ë¢°ë„ í‰ê°€**")

                relative_rmse = evaluation_results['relative_rmse']

                if relative_rmse < 3:
                    confidence = "ë†’ìŒ"
                    confidence_color = "green"
                    confidence_text = "ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤."
                elif relative_rmse < 5:
                    confidence = "ì¤‘ê°„"
                    confidence_color = "orange"
                    confidence_text = "ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
                else:
                    confidence = "ë‚®ìŒ"
                    confidence_color = "red"
                    confidence_text = "ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ê²°ê³¼ í•´ì„ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."

                st.markdown(f"**ì‹ ë¢°ë„ ìˆ˜ì¤€:** <span style='color:{confidence_color};'>{confidence}</span>",
                            unsafe_allow_html=True)
                st.write(confidence_text)

        except Exception as e:
            st.error(f"ëª¨ë¸ í‰ê°€ ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logger.error(f"ëª¨ë¸ í‰ê°€ ê²°ê³¼ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")
            logger.error(traceback.format_exc())

    def get_prediction_data(self, symbol):
        """ì˜ˆì¸¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        data = load_and_preprocess_data(symbol)
        prediction = create_and_evaluate_model(data)
        return prediction

def load_and_preprocess_data(symbol):
    """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
    data = load_data(symbol)
    preprocessed_data = preprocess_data(data)
    return preprocessed_data

def create_and_evaluate_model(data, model_type='lstm'):
    """ëª¨ë¸ ìƒì„± ë° í‰ê°€"""
    model = create_model(data, model_type)
    evaluation = evaluate_model(model, data)
    return evaluation

def display_prediction_results(prediction_data):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
    st.line_chart(prediction_data)